{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the HGP-SL model on the hERG training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import enlighten\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from layers import GCN, HGPSLPool\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU, GRU\n",
    "import torch_geometric.transforms as T\n",
    "from torch_sparse import coalesce\n",
    "from torch_geometric.data import (InMemoryDataset, Data, download_url)\n",
    "from torch_scatter import scatter\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "\n",
    "#RDKit\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdchem import HybridizationType\n",
    "from rdkit.Chem.rdchem import BondType as BT\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import RDLogger\n",
    "\n",
    "RDLogger.logger().setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "import time\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fcts\n",
    "def show(df):\n",
    "    \"\"\"Render the molecules within a DataFrame correctly\"\"\"\n",
    "    return HTML(df.to_html(notebook=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay = 1511\n",
    "global dataset\n",
    "# filename = f'{assay}_dataset.pt'\n",
    "dataset = f'{assay}_dataset.pt'\n",
    "global input_sdf\n",
    "input_sdf = f'{assay}_compounds.sdf'\n",
    "global directory\n",
    "directory = f'{assay}_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup dataset\n",
    "sdfpath = os.path.join(os.getcwd(), f'{assay}_compounds.sdf')\n",
    "backup_df = PandasTools.LoadSDF(sdfpath)\n",
    "dataframe = backup_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUBCHEM_ASSAY_ID</th>\n",
       "      <th>PUBCHEM_SID</th>\n",
       "      <th>PUBCHEM_CID</th>\n",
       "      <th>PUBCHEM_ACTIVITY_OUTCOME</th>\n",
       "      <th>PUBCHEM_CANONICAL_SMILES</th>\n",
       "      <th>ID</th>\n",
       "      <th>ROMol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1511</td>\n",
       "      <td>56314828</td>\n",
       "      <td>1988</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>CCC1=CC=CC(=C1N(COCC)C(=O)CCl)C</td>\n",
       "      <td></td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1511</td>\n",
       "      <td>56321651</td>\n",
       "      <td>425322</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>C1CCC(CC1)NC(=O)C2COC3=CC=CC=C3O2</td>\n",
       "      <td></td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1511</td>\n",
       "      <td>56322145</td>\n",
       "      <td>24981957</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>C1CN(CCN1CC2=CC=CC=C2)S(=O)(=O)C3=CC=CC(=C3)C(...</td>\n",
       "      <td></td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1511</td>\n",
       "      <td>51090143</td>\n",
       "      <td>7384392</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>CCS(=O)(=O)N1CCC2(CC1)N(CCO2)S(=O)(=O)C3=CC=C(...</td>\n",
       "      <td></td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAAABmJLR0QA/wD/AP+gvaeTAAAf30lEQVR4nO2dd1wU1/rGn9lCL7ugIE3ELigaUcQgtpiYGCFGbNdCjOZDTFQUu+ZniDGxxEYkuTHG3ARNvLGAxC6xRUBFsKCgSEBFBSlSdqnLlvP7Y7iIKIrszNb5fvzDOTO877PyeM7ZM6dQhBBwcDANT9sCOAwTzlgcrMAZi4MVOGNxsAJnLA5W4IzFwQqcsThYgTMWBytwxtI95HJ88QX8/eHnh9mzIZVqW1Br4Iyle3z2GQoL8fffuHgR7u6YOlXbgloDxb3S0Tns7XH3LmxsAEClgrs7UlLQrp22Zb0aXI2lY0gkEAjqXQWAx0PHjrh/X6uaWoPuGaukBJcuobhY2zq0hLU1amuhVD4pKSqCg4P2BLUSgbYFPM2yZTh1CgMH4tIl9O+PrVtBUepHvXPnjrLxr6q1tGnTRiwWqx/nRfB4ePNN/PorZs4EgIQEmJnB3Z3dpGxAdIfjx0lAAFEoCCFEqSRvvkn271czpEwm27p1q0gkYuTfat68eX/++ScDn/TFPHxIBg8m775Lxo0jr71G0tLYTpiUlHTmzBlmY+pS533JEri7Y/bs+svoaFy8iB9+UCfkhg0blixZYmtr27ZtWzXV1dXVPXz4UCQS/fPPP3Z2dmpGexEqFSgKjx+jthZubvWXTNTcz0WhUPTp0ycjIyMmJmbs2LGMxWXWp60kPZ3cv08++ojs3Pmk8MABMmmSOlELCwttbW0BHDt2TF2FhBBCRo4cCWDOnDmMRHs+O3cSgEydWn/51VcEICtWsJdw69atADp27FhbW8tgWK123jMy8MUX8PREz574/nt06oTMzCd3b95E587qhF++fLlEIgkKCnr77bfVlQoA2Lx5s1Ao/OGHH27cuMFIQK1TVla2atUqAJs3bzY1NWUyNIMmbREqFblwgSxaRDw8CFD/p21b8sUX5NEj0qEDSUoihJCUFOLhQXJzW53nypUrPB7PxMTk9u3bjIknZM6cOQCGDx/OYMyn0GyNNXv2bJY+joaMpVAo7icmkrAw4ur6xE/OzmT2bHL6dH2HnRCSnk4mTSJ+fmT8eHLtmjoZBw8eDGDx4sUMqG9EaWmpvb09gLi4OGYj16NBY2VkZAgEAj6ff/36dcaDs2sshUKRkJAQFhbm5OQ0wNmZUBQBSPv2JCyMJCQQpfIlP5+SQsaMITU1r5p39+7dABwcHMrLy1spvXlY6pTUo0FjsdplZMVYtbW1hw4dmj59euNvT126dJF8+SVJSWlpFKWS9OxJADJ79itlr66udnd3B7Bjx45Xlt4CFApFr169AKxbt4756Joy1oEDBwCIxeLi4mLGgxPGjRUbGzt58mSbhjcSQM+ePSMiItJaNxhz/ToxMyMAeZV2JyIiAsBrr72mfGmN2Fri4+MB2NqKCwoqGA6tEWPJZLIuXboAiIqKYjZyA0waKysri/6vDMDT0zMiIuLmzZvqBt28mQBELG5hR/7BgweWlpYA/v77b3VTv5DQ0K2enpUffshwWFXsf1UebsrwT+hLZdRGlYebcsNqZrOsXbuW/h3V1dUxG7kBJo01ZswYANOnT7979y5jQVUqEhhIADJ48JM+fvNMmjQJwCT1BsBaQk4OMTUlPB5JTmYy7OPHO1NTcedOfY2Vn/9VaioePmSyxiooKKCblOPHjzMYtgnMj2MFBQV16NCBsXAUhZ9/hpMTzp3D2rUvfvb8+fN79uwxNzdft24dYwKaoWNHzJsHlQrz50N3Xl60hGXLlkml0jFjxtCdd5bQvdkNz9K2LXbvBp+PVauQlNTcUyqVav78+YSQJUuWuGvkre3//R+cnHDhAv77Xw1kY4YrV67s3LnTxMTkm2++YTWRPhgLwNChWLQICkXd9OkV5eXPfeSXX35JSUlxdXVdvHixZkRZW+OrrwBgyRJUVWkmp1oQQubPn69SqcLDw+nOO3voibEArF6dExj4ulA4MzT02ZsVFRUrV64EsGHDBrrzrhmmT4evL/LywPL/f2bYvXt3QkKCo6Pj8uXL2c6lP8YSCqnIyOz8/H379u3YsaPJzdWrVz969GjgwIETJ07UpCgeD5GRoChs2IB79zSZ+ZWpqalZsWIFgLVr19Lv5llFf4wFdOzY8aeffgIwb968W7duNZTn5ORs3bqVx+N9++23FGvTS5pj4ED861+oqcHSpRrO/GqsXbv2/v37ffv2/eCDDzSQTp+MBWD8+PHTp0+vrq6eMGFCTU0NXRgeHi6TyT788MP+/ftrRdW6dbC1hbMzVCp1QwmFTtbWw83NvehLU1MPa+vhpqad1Az74MGDTZs2URQVGRnJ42nkl87g0AU9jhUbG8tgzGeprKzs3r07gLCwMELIyZMnAVhbW+fn57Oa98WUl5MtW0h2dv3lkSNP/t4KVKq6srKYwsKtUulJQlTqy5swYQKAyZMnqx+qheifsQghly9fNjU1pSgqJiaGHuv/5ptv2E76UsRi8sYbRKUihJAPPySHDrU+VHb22Nzcj4uLf37wYIH6xkpMTKQoytzc/N69e2qGajk6tpiiZfTt23fNmjULFy4MCQmpqqrq1KlTWFiYtkXB3Byurti1CyEh9SUqVbNjp3y+ijRzj6L4Umm8t/cDPr9hqn6zDwOgKEqpbPZuw/DesmXLNDO8R6OXxgIQHh5+5MiR06dPA9i0aRPDsx9by9q1CAjA6NH1l66uePTo+U+ePdvDyirrubf69CkXi9/PynrTwSFMLB7H45lfv+4qlzcTCAA8+/W7+QJV5ubm7du319jwHo2+GosQ0rCii5GlXYzg5IQ5c/DZZ/WXfD6a7yhTzX9zojp0+LWiIqGk5D+Fheu7d79IUfwXfM0ihPfi/viiRYuCgoLMzc1f/gEYhMFmVWN9LEII/TbQysoKgIeHR82rTwZkHGdnQgiRy0nfvsTXV60+VgO3bw+VSk8xEEjj6NlwA01qaurnn39OUdTvv//u7e199+7dzZs3a1tUPQIBoqKQktL6CIQoCwrWV1ael0gOyWQ5ZmaezKnTHPpnrMrKyilTptTV1S1YsCAoKCgyMhLA2rVr8/PztaiqtBQrVtT//fXXER2NHj1aHUxlYuJWVra3ouJc586HhEI92w6kHgZrP800hVOnTgXQt29fmUxGl9DLLENCQljN+wLu3SPW1uTTT18+if+lVFZeun9/zuPH9esrJZIT9+/PKS9nolnVLHpWY0VHR//222+Wlpa7d+82MTGhCzdu3GhmZrZr167k5GStqFq8GBUVkEhe0FVvKbW1mUVF30ml8fRlVVVKUdF3lZUX1I2rcfTJWDk5OfR41ffff9+tW7eGcg8Pj/DwcEIIPWCjYVVJSdi/H+bmWLNGw5l1Gr0xVl0dFi0SiUQ+kydPfvY16ooVK5ydnS9evPjbb79pUpVKhXnzQAiWL0f79prMrOvojbFWrEBcnL1IdPKHH7Y9e9fKymrNmjUAlixZItXgpp07duDyZbi5YeFCjeXUD/TDWCdOYPNmCATYto1nY2P93GdCQkIGDBhQUFDA9qTbBqRSREQAwMaNsLDQTE69QQ+MVVSE6dNBCFavxsCBzT5GzwmhKGrjxo3Z2dkaELZqFQoK4O+P8eM1kE3PYN5YMTExWVnPfwvWCgjBjBkoKMCQIXjpyy4/P78pU6bIZDINTL3Nzsb33z+ZQcrRFAaHLu7cudOzZ086rKen59KlSxMSEtSMuX59/W40eXktev7hw4f0e574+Hg1U7+YGTMW9+qV9NFHDIeVH92jGNxHvjq8/vLXSMXgPvIfWVjLzzIML7F/dsuGrl27Ll++PDU1tRXRUlOJiQmhKPJK+zOuXr0agJeXl1wub0XSlnDs2DEAIpGosFDKcGiNb7zGEqxsClJXV3fixInQ0FCHRtv9dujQYc2aE0lJLR2erq4mnTsTgMyf/2rZa2pqPDw8AGzbtq0V4l+KXC738vICsGnTJuajc8ZqCUqlkt7GyNXVFUDnzul0uzZtGjl4kLx034DoaDJwYCt2MSL79u0DYGdnV1JS0jrlL4B+4d25c2d938aIVTS08ZpKpbpwIeXZffxCQ8mJE/UOKykhI0aQjIz6H5k3jzx4UD/TtxUMHToUAD0izyAlJSV0Q3/48GFmI9fDGavVXL5MVqwg3bo9cZhYTD74gCQlEbGYDB1abyZ/f6LOJo/Xrl3j8/kCgSA9PZ0p5YSQjz/+GMCIESMYjPkUhmIsLYxj9e2Lr79GZibS07FuHfz9UVaG6GjwePDwgLs7oqMZyNK7d++PPvpIoVDMnz+fgXAAgIyMjJ9//lkgENBzdThegDYHSL28sHQpEhORlYXt20FvUbNuHb76CiUlDMRfvXq1SCQ6efLk0aNHGQgHhIeHKxSKOXPm0J13jhegQwcIFBTg3Xdx+TK2bkVmJq5fx3/+g65d1Yq5ZcuWBQsW2NjYqH84hVwuLyoqEovFWVlZLB58UlsLiQTm5jAzg1IJlQqVlbCyggY3pGAEXVxMMXs2/PzAyITQOXPmWFhYLF++/D4TB2iFh4ePGDGC3eN0zMxQUYGpU1FaChMTKBTYsQOOjixmZAddrLEApKTAzw+3bqlbY9E8fPiQkZU8YrG48faqbDF5Mvz8QK+UPHIEERFISdG710Y6ZCy5HNnZT6aKx8Xh7bdhZqZVTZqHEIjFKC6GUFhf0q0b4uP17gAwHZrdIBTWu4oQ9O6NsWNRUKBtTZpHKoWp6RNXAWjXTh//IXTIWA1QFLy8QAhiYrQtRfPY2kIuf7JBICG4d0/vqivoprEABAcDMEpjAZg2DatW1e/6sGMHPD317kBo6FQfqzHV1XBwQHU1cnPh5qZtNRqmuhrLluHSJRCCzp0RGQm1D1vUPDpqLADjxiEmBlFRmDNH21I4Xh0dbQph5K2h/qO7NVZFBRwcIJcjP18fT3E3dnS3xrK2xk8/nUhMHAn8wlhQlUo/dmTXf3TXWADeeeeRUBgvkfzBQKy6OoSFoX9/BAXBxwdnzzIQk6N5dPFdYQMi0RiK+rii4oxCUSoQvPrB8ZWVOHoU3bvD2xtRUZBKkZICHg///IM33kBaGlh962fc6HSNxeeLrK2HEiKXSA69wo+Vl2PfPoSEwMkJEyfixx8BIDYWYWH1u3Z06YJBg3DmDCuiOQDoeI0FQCwOlkrjy8pi7O1ftu3948eIi0NMDE6fRl0dAPB4CAiAry8AFBY+NUfA0RGFhayp5tB5Y4lEY+/fny2VxiuVUj7/OTML5PJH5eUHyspiOn4qFZxKBQCBACNGIDgYY8Y8GbN2c0NuLlxc6i9zczFihGY+gnGi68YSCNpYWflXVPwtkRy1s5vUUF5Xl1tWFlteHltZeR5QAZC8PdTedBSCg/Hee7C3bxooJARr1mD/fpiZITkZ169j+HBNfhBjQ9eNBUAsngDwBIL6KaCFhVvKyv5bVZUKEAA8nrmNzdticbBtn9FY9PTZQ4QgNRUxMUhOxsmTePwYgweDx4OtLf78ExreRdjI0N0B0saoVDVlZXvk8kfm5j2Li3+QSI7xeObW1m+IxeNFovf5fOsmT+P8ecTEIDYWDRNHL12Clk7aMU502ljV1VfNzXtRlOCff962sOhtYeFTW3vL2nqYQlFuY/MWj/fUJEBClPKcRJMte3HgwJN9+93cMHYsgoPh78/ARo4cLUYXjVVTk1FWtq+s7I/a2ttdu56yth5+9aqFt3d+oyNAnkCIsqrqQlnZvrKyvcIi9BhZBJUK7u547z2MHw9/f72b1GsY6E4fS1VZmUj3x+vqHtBFQqGTQlEMwM5u6u3bAW3bfmpnN4X+bqhS1Uil8eXlMeXlh5TK+sN8+U49lN/O4w96G336aOtjcNBou8ZSKHD2LA7FpU+Pk6ny6DITE3exeKxINNbK6vWGIdyqqpSSkl8qKk53736pqupCTs44laqSvmVh0UckChaLx+rpXvsGiZZqLKUSFy5g3z7s2UMPVIr7+JT2E4pEQWLxeCsrf6Bp+2Vp2d/Ssv/t20Nqaq6Zm/chpMbMzFMsHm9n9y8zs27Py8GhTTRrLJkMR48iJgaHD0MiqS/08kJwcLvB41069WzyuEJRUl7+JyEKufy+tfUwubygru6umZmnQNDG2ztfIOAm0+gumm0KJRI4ONS/b/H0xPjxmDABnk3bL4XisURytKxsn1R6ghC5iYmrm1tUdfUVihLa2U0yNe2iOcEcrYVlY929i9mzUVICpRKvv4716/H553B0xNix6NixybNy2YMySWxZWUxlZRI9mE5RJjY2b4hEwfb2H1CUoLY2s6BgvVDo6OKyjkXNHEzAprFUKvTrh6++wqhRIARz58LSEuvXN30sNxdxcdi3r8ZTcPPjvwHweGbW1iNEokCR6H2B4Mk6gpqaGzdvegsEbby9H1GU7nyf5XgeLG6RdP068fF5cllYSFxdn1zevElWryZ9+jRsk6Xq2iknZ0Jp6R6lsqK5kOnp3VNTIZWeZVE2BxOw+f8+P//JbAIADg4oKYFKhd9+w7p1uHWrvlwkwujRCA6mRo7s+LL3dyLR+wUFa8vLY6yth7Cmm4MB2HzL4ez81JYxxcWwtwePh6oq3LoFOztMm4aDB1FQgF27MGZMS94Ki8XBAMrKYuk30Bw6C5s1lqcnZDKcOYNhwwBgwwZMmgQA48eja1cMHQo+/1VDWlj4mJp2lMnuVFVdtLRs/pgKDm3D8rfCzEzMmgWVCjIZvLywdSusrNQM+fDhosLCTY6OC11dNzKikYMNNDKOJZNBKGRqckFV1YXMzNdNTDr06nXn2QF6Dh1BIzNJTE0ZnLJiaelnYuJWV3evuvoqUzE5GEcfpyhRtrZjsrN7Hj9+SttKOJpF27MbWsW5c2eHDBnWrVu3zMxMbWvheD56aSyVSuXi4lJQUHDjxo2G88Y4dAp9bArB4/GCgoIAxHCb0egqemksAMHBweCMpcPoZVMIQC6Xt2vXrrS09NatW927d9e2HI6m6GuNJRQKAwMDARw4cEDbWjieg74aC1xrqNvoa1MIQCaTOTg4SKXSnJycjs9MG+TQLvwvvvhC2xpaiUAgSEhIyM7OPnfuXHl5uVwut7e3NzU11bYuDkCva6ycnJwBAwYoFApJw7oMoGPHjv7+/j4+Pj4+Pv379+d8pi301VjFxcWDBg3KysoaNGjQzJkzr169mpycfO3aNZlM1vCMubl53759fX19fX19BwwYQJ9AzqEZ9NJYFRUVQ4cOvXLlSr9+/c6cOWP1v6k4CoXi9u3bly9fTkpKSkxMzMzMVKlUDT9la2vbs2fPQYMG+fv7+/n5tdXDXfn1CP0zllwuDwwMPHHiRKdOnZKSkhybP8uvoqIiLS2N9llCQkLB00cdOTk5+fj40D7z8fEx53Y1YhZtTbZvHSqVKiQkBEDbtm2zsrJe6Wfv3bu3d+/ehQsXBgQEWD59YKlQKIyIiFAoFCzJNkL0zFgLFiwAYGNjc+XKFbrk4cOHaWlprxpHoVCkp6dHR0eHhYX5+/sLhcIOHTrMnDmTab3Giz4Z65tvvgFgYmISHx9Pl5SVlfXq1cvW1jY5OVmdyFevXgVgb28vl8uZUMqhP8bavXs3j8ejKGrnzp10SU1NTUBAAABPT8+SkhI143t6egL466+/1FbKQYi+GOvUqVP0iNSWLVvoEqVSOW7cOAAuLi65ubnqp/j8888BzJo1S/1QHEQvjJWSkkIPKCxbtqyhcO7cuQBsbW1b0cFqTEPbl5aWBsDR0ZHrwjOCrhsrOzubHlCYMmWKSqWiC1etWgXA3Nw8ISFBneCzZs0Si8UNFV63bt0AnDt3Tl3RHDpurKKioq5duwIYNWpUQ9Xy008/AeDz+TExMWrGnzBhAoDIyEj6cunSpQDmzZunZlgOosvGkkqlffv2BdC/f/+KivptQg4dOiQQCABERUWpn2LPnj0AAgIC6MtLly7RnbaGqpGj1eioserq6t566y0AnTt3LiwspAsvXrxID2yuWrWKkSxVVVUWFhY8Hi8vL48uod8nXrx4kZH4xowuGqtheN3Jyenu3bt0YUZGhp2dHYDQ0FAGc40ZMwbAv//9b/oyPDwcwOLFixlMYZzoorHo327j4fW8vDx3d3cAgYGBzI5h7tq1C8Abb7xBXyYmJgLw8PBgMIVxonPGWr9+fZPh9fLy8t69ewPw8/OrqqpiNl15ebmJiQmfzy8qKiKEKJVKZ2dnAA2e5mgdumWs5ORkiqJ4PN6ePXvokobhdS8vr9LSUjaSvvPOOwB+/vln+vLTTz8F8Nlnn7GRy3jQrcUUeXl5Li4uEyZMoAcCABQVFeXl5bm5uR0/flzMzkm7TRZl0Jf79u1jI5cRoW1nP8Wvv/4K4K233mpc+OjRo8zMTPaSPn78WCAQCIVCukZUKBQODg4AMjIy2Etq8OhWjfXee++ZmJicOXOmtLS0obBdu3b0mDhL2NvbDxkyRC6XHzlyBACfz+fW76uPbhlLJBINGzZMLpcfPHhQk3mf2xpyxlILbVeZTdm+fTuA0aNHazJpQUEBn883MzOTSqWEkLq6OnrMjNUm2LDRrRoLwPvvvy8QCP766y+pVKqxpI6OjgMHDqytrT1+/DgAoVA4evRoAHFxcRrTYGDonLHatGkzaNAgmUxG93g0BtcaMoy2q8znEBUVBSA4OFiTSR88eEBRlJWVVXV1NSGktrbWxsaGoqh79+5pUobBoHM1FoBx48bxeLxjx45VVVVpLKmrq2t4eHhUVBRFUQBMTU3feecdQkhsbKzGNBgU2nb28xk4cCCA/fv3a1HD3r17Afj7+2tRg/6iizUWdKOLI5FILCwspkyZokUN+ovuGouiqMOHD9fW1mpFwKFDhz755JPq6mqhUKgVAXqPtqvMZvHx8QFw6NAhzadmfEahEaKjNRa01xrevHlz1KhRVVVVoaGh9JowjtagbWc3S1ZWFgCRSCSTyTSWlL0ZhcaG7tZYXbp06dmzZ3l5+dmzZzWTUSKRjBo1Kjc318/P748//qBXbXC0Dt01FjTbGtbW1gYGBqalpXl5eR05csTCwkIDSQ0ZbVeZL+LGjRsA2rRpw3arpFQqaRMztWCfQ6eNRQihDwc4e/ap08UvX74cFxeXn5/PVBamFuxzNKDrxlq+fDmAuXPnNi6cNWsWXd06OTmNHj06IiLi4MGDrZ4RT+8brf6CfY7G6LqxUlNT8czq5G3bto0YMcLW1rZxm87n83v16jVz5szt27dfu3atha0nPf2LkQX7HI3RdWMRQujDAc6fP//srby8vL1799K78pmZmTX2maWlpb+/f1hYWHR0dHp6+nNXzTcs2P/uu+/Y/xzGhR4Yi94ecuTIkTdu3HjBHkO1tbUXLlz49ttvp0yZ0qVLlybfURITE5s83zC8/uWXX7L8CYwRPdg1OTU1df369fv37wdgZWXVu3dvn//h5eXV3E+VlpZe+h9XrlzJzs5uPIJw8+bNgICA0tLS0NDQH3/8URMfw8jQA2MBSE9P//rrr5OTk+/evdu43NnZecCAAfT5AD4+PjY2Ni2JlpeX5+/vn5ubGxQUFBMTww2EsoF+GKsBiUSSkpKSmJh4+fLl5OTk4uLixndbct6JRCIZMmRIWlqan5/fqVOnuIFQltAzYzUhPz+/4RyKK1eu1NTUNNwSCoXe3t4NPvP09KQoqqamZuTIkQkJCV5eXgkJCSwtreaAvhurMXV1ddeuXWvoV9HHCzTcbdu2ra+v74MHD65fv96+ffukpCRXV1ctqjV4DMdYTXjueSft27enO/U9evTQtkADx2CN1YTc3NxTp06FhobyeLzCwkKuEWQbnZ7dwCDu7u4zZsyg1+8fPnxY23IMH2MxFo0urNEwEoylKaQpLCx0cXERCARFRUUtHPTiaB3GVWM5Ojr6+/vLZLJjx45pW4uBY1zGAtcaagrjagoB0BtPmpubFxUVNTkOk4NBjK7GcnFx8fX1ra6ujo+P17YWQ8bojAV60xGKun/mjLaFGDJG1xQCKL1719bfn19djcJCPO9FNYf6GGONZefhwW/XDhIJTp3SthaDxRiNBQDBwQDAfTdkDWNsCgEgKwvdusHeHgUF4Cb6sYCx1lhdu8LTEyUl0NT6fWPDWI0FYNw4gGsN2cJYm0IA16+jd284OiIvD3y+ttUYGkZcY3l7o1s3FBbi/HltSzFAjNhYAMaMAbjWkBWM+wvRpEmorMTEidrWYYAYcR+LJjERu3ahtBT9+2PePG4gnimMuyk8cQJz52LGDGzejKoqBAVpW5DhYNw11vDhWLkSw4bVX/r4YPt2+PhoVZOBYNw1VlYWvL2fXPbpg8xM7akxKIzbWFZWaHxcT2UluInwDGHcxgoIQMNSsMpKXLiA/v21KshwMO4+Vl4eAgMREABnZ+zfjxkz8Mkn2tZkIBirsRISEBAAADIZLl5EaSn69YObm7ZlGQ5GaazoaHz4IUJDsW2btqUYLMbXxzp6FB99BELg6altKYaMkRkrJQUTJ0KhwMqVCAvTthpDxpiawuxs+PujqAjTpiE6GhSlbUGGjNEY69EjvP467t3Du+8iLo6bjsw2xmEsqRRDh+LqVfj64vRpcAug2cfw+1gymWzXwoW4ehU9euDoUc5VmsHAjaVSqUJCQkJ27IgIDMTx47C317YiY8HAjbVw4cK9e/fa2NiMXb0a7dtrW44RYcjGWrNmTWRkpImJSWxsbO/evbUtx7gw2M7777//Pm3aNIqi9uzZM45e6cWhQQzzW/fRo0enT59OCImMjORcpRUMsClMSUmZOHGiQqFYuXJlGDe8riUM0FjHjh2rrKycOXPmqlWrtK3FeDHMPlZsbGxQUBB3rJcWMUxjcWgdA2wKOXQBzlgcrMAZi4MVOGNxsAJnLA5W4IzFwQqcsThY4f8BHhK6oEZMMH4AAAGSelRYdHJka2l0UEtMIHJka2l0IDIwMjIuMDMuNAAAeJx1kL1Lw0AYxt9cmsu1aZuatkkVC8WpY3fFBMFuumidW0EJgijoLKKDIg4Kbp0UFBFc3PxqIgUHBQcd/fgXHEQUHOrlTT9CoS88PL977rmEu8/a+QfwiYE/AtcA1yDXukCh7GWi74QkIMedMshzE0nLZYzbrY57cag77tFmGPf6BbXQQ9SyPReFAPTaaZ9t3kLhtxMIEJEREuKSQKJAZZAZsDCEI8AUUKIQjUEsDooKaoIRtY9LAy1pk2SqnErbJK2XdYNbJpfph4gEcQaGVk6JVIqEmUylqMLiMZpMpXVDM8YE/0lx+LueWkfjJ6a/3LOgPVYXu2aAHZ9bGeYm/04zt5wOt7rt3Az0ke8XM+7vVBV7hesV1+sFONhBPtj6duZ/8q7HjYu/2sKEgryvzrizh0XkUuHKsYc2kB+ms678dIxcLTWcm9UX5MeE7DwvvSNX6l+jlfol8vDy5Mhadhf5rbh5+7oj3Xk8d7btJCsGsv4P+ldoPEbpmdcAAAIIelRYdE1PTCByZGtpdCAyMDIyLjAzLjQAAHicjZVdjuMgDIDfewouUISNMfA4bUer1WpSaae7d9j3ub/Whqa4Co0mLVZMvhj8Rw5Or9+XX/++3OPCy+HgXNj511rd3xhCOHw4vXGn9x8/F3e+vZ3WmfP1z3L7dMgOi7wjv2f27Xb9WGfAnV3ymMSgKB5r1ZvgQ7vGmygc+XSffTzecNF9urh9vOHIXQcHW8Mrlyx33AHZLTM7Gy6LI8HntBp86XER8Pgtsir5nbUhPNncMQlgt7kHovh9RB8L5Ps2IaY5GnX16EsoUdGH+QlKT+geqQka6+8tz1Iasr8KBXV59EwB5mhWo8FTBe4oZOY5WhSNPhI1/6OHEF+g9zxRomaVfGDO82pviUJBe6iShwI0R6FbrZWKouw5lHmsEHv6E2buaAXN6wyNLf+UGfr6JaR5rJAaGQDvTsVc5v5j6lENTM1okaDxC6e4OxU4t6hWTww4Rd+Xy9OB0o+Y03W5jCNGfzhOElFcHAeGKI7GuaBqGu0PovJocpCRRy+DjDI6FmTU0Zagw3YfNAGmyxqCppugiWiaBpog0xvQRDI90N9iU+uqSiGbku4zxVQutJlqCpRUoK1DUoFgyo1UIJqqIhUYTfGQCiRTJNCYZIoBVCCbnINGZExoeMW3x/7ka0LNVLXJt6lWff0Syf3hPwsvQ8AJMPerAAAA6XpUWHRTTUlMRVMgcmRraXQgMjAyMi4wMy40AAB4nFVPQW4EIQz7So8zEkQxhABa9ZT7zqFP4Bv7+BIYjdoDJHYcWzH7Ob6v098bZpYOM5yX2Ts9g4ExxnHZOQa+PkehVAIo9R5eQiVweOX9YaJZ4qrYI6ZanFny+B/dks3e5N8+JsoN1SHytIyZGrcZ5poHxRve4vioQR0thTlQYawc6VAnUFWXQxaZK5nAWdeKFJkKIVaty1SKZxRCg2zTLi1EJeW2PEuq6rjjPpFVEGKb3ro3WOsM6SSK5BdKVbhl4wLHjLQyc20azs8vdhdR6la55W8AAAAASUVORK5CYII=\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1511</td>\n",
       "      <td>51090795</td>\n",
       "      <td>7423030</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>CC1=NC(=NC=C1)NC(=O)CCN2C(=O)C3=CC=CC=C3S2(=O)=O</td>\n",
       "      <td></td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(dataframe.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "global element_dict\n",
    "elements = []\n",
    "\n",
    "if os.path.exists('element_list.json'):\n",
    "    pass\n",
    "else:\n",
    "    with open('periodictable.csv', 'r') as ifile:\n",
    "        reader = csv.reader(ifile)\n",
    "        for i in reader:\n",
    "            element = i[1]\n",
    "            elements.append(element)\n",
    "\n",
    "    indexes = [i for i in range(len(elements))]\n",
    "\n",
    "\n",
    "    element_dict = dict(zip(elements, indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to file for future use\n",
    "import json\n",
    "\n",
    "if os.path.exists('element_list.json'):\n",
    "    with open('element_list.json', 'r') as listfile:\n",
    "        element_dict = json.load(listfile)\n",
    "else:\n",
    "    with open('element_list.json', 'w') as listfile:\n",
    "        json.dump(element_dict, listfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists\n"
     ]
    }
   ],
   "source": [
    "#setup filesystem\n",
    "import shutil\n",
    "\n",
    "rawdir = os.path.join(directory, 'raw')\n",
    "processdir = os.path.join(directory, 'processed')\n",
    "\n",
    "try:\n",
    "    os.mkdir(directory)\n",
    "    # rawdir = os.path.join(directory, 'raw')\n",
    "    # processdir = os.path.join(directory, 'processed')\n",
    "    os.mkdir(rawdir)\n",
    "    os.mkdir(processdir)\n",
    "except FileExistsError:\n",
    "    print(\"Directory already exists\")\n",
    "    pass\n",
    "finally:\n",
    "    shutil.copyfile(os.path.abspath(input_sdf), os.path.join(rawdir, input_sdf))\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[\"PUBCHEM_ACTIVITY_OUTCOME\"].replace(\"Inactive\", 0, inplace=True)\n",
    "dataframe[\"PUBCHEM_ACTIVITY_OUTCOME\"].replace(\"Active\", 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    304127\n",
       "1      1552\n",
       "Name: PUBCHEM_ACTIVITY_OUTCOME, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.PUBCHEM_ACTIVITY_OUTCOME.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global targets\n",
    "targets = dataframe.PUBCHEM_ACTIVITY_OUTCOME.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioAssayDataset(InMemoryDataset):\n",
    "    def __init__(self, root=None, transform=None, pre_transform=None):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [input_sdf]\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [dataset]\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        data_list = []\n",
    "\n",
    "        bonds = {BT.SINGLE: 0, BT.DOUBLE: 1, BT.TRIPLE: 2, BT.AROMATIC: 3}\n",
    "        types = element_dict\n",
    "\n",
    "\n",
    "        # mol_list = Chem.SDMolSupplier(self.raw_paths[0], removeHs=False, sanitize=False)\n",
    "        mol_list = Chem.SDMolSupplier(self.raw_paths[0], removeHs=False)\n",
    "        pbar = enlighten.Counter(total=len(mol_list), desc='Encoding molecules...', unit='ticks')\n",
    "        for ID, mol in enumerate(mol_list):\n",
    "            #number of atoms\n",
    "            n_a = mol.GetNumAtoms()\n",
    "\n",
    "\n",
    "            conf = mol.GetConformer()\n",
    "            pos = conf.GetPositions()\n",
    "            pos = torch.tensor(pos, dtype=torch.float)\n",
    "\n",
    "            #atom features\n",
    "            type_idx = []\n",
    "            atomic_number = []\n",
    "            aromatic = []\n",
    "            sp = []\n",
    "            sp2 = []\n",
    "            sp3 = []\n",
    "            num_hs = []\n",
    "        \n",
    "            for atom in mol.GetAtoms():\n",
    "                #need to implement this\n",
    "                type_idx.append(types[atom.GetSymbol()])\n",
    "\n",
    "                atomic_number.append(atom.GetAtomicNum())\n",
    "                aromatic.append(1 if atom.GetIsAromatic() else 0)\n",
    "                hybridisation = atom.GetHybridization()\n",
    "                sp.append(1 if hybridisation == HybridizationType.SP else 0)\n",
    "                sp2.append(1 if hybridisation == HybridizationType.SP2 else 0)\n",
    "                sp3.append(1 if hybridisation == HybridizationType.SP3 else 0)\n",
    "                num_hs.append(atom.GetTotalNumHs(includeNeighbors=True))\n",
    "\n",
    "            z = torch.tensor(atomic_number, dtype=torch.long)            \n",
    "\n",
    "            #bonds\n",
    "            row, col, edge_type = [], [], []\n",
    "            for bond in mol.GetBonds():\n",
    "                start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "                row += [start, end]\n",
    "                col += [end, start]\n",
    "                edge_type += 2 * [bonds[bond.GetBondType()]]\n",
    "\n",
    "            edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "            edge_type = torch.tensor(edge_type, dtype=torch.long)\n",
    "            edge_attr = F.one_hot(edge_type,num_classes=len(bonds)).to(torch.float)\n",
    "\n",
    "            # perm = (edge_index[0] * n_a + edge_index[1]).argsort()\n",
    "\n",
    "            # # print(edge_index[0])\n",
    "            # # print(edge_index[0])\n",
    "            # # print(n_a)\n",
    "            # edge_index = edge_index[:, perm]\n",
    "            # edge_type = edge_type[perm]\n",
    "            # edge_attr = edge_attr[perm]\n",
    "\n",
    "            # row, col = edge_index\n",
    "            # hs = (z==1).to(torch.float)\n",
    "            # num_hs = scatter(hs[row], col, dim_size=n_a).tolist()\n",
    "\n",
    "            x1 = F.one_hot(torch.tensor(type_idx), num_classes=len(types))\n",
    "            x2 = torch.tensor([atomic_number, aromatic, sp, sp2, sp3, num_hs], dtype=torch.float).t().contiguous()\n",
    "            x = torch.cat([x1.to(torch.float), x2], dim=-1)\n",
    "\n",
    "            #target is the binarised activities\n",
    "            y = targets[ID]\n",
    "\n",
    "            name = mol.GetProp('_Name')\n",
    "\n",
    "            data = Data(x=x, z=z, pos=pos, edge_index=edge_index, edge_attr=edge_attr, y=y, name=name, idx=ID)\n",
    "            data_list.append(data)\n",
    "            pbar.update()\n",
    "        torch.save(self.collate(data_list), self.processed_paths[0])\n",
    "\n",
    "    #need to add process functions for the molecules\n",
    "\n",
    "# class MyTransfrom(object):\n",
    "#     def __call__(self, data):\n",
    "#         print(data)\n",
    "#         data.y = data.y[:, targets]\n",
    "#         print(data.y)\n",
    "#         return data\n",
    "        \n",
    "class Complete(object):\n",
    "    def __call__(self, data):\n",
    "        device = data.edge_index.device\n",
    "\n",
    "        row = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
    "        col = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)\n",
    "        col = col.repeat(data.num_nodes)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "        edge_attr = None\n",
    "        if data.edge_attr is not None:\n",
    "            idx = data.edge_index[0] * data.num_nodes + data.edge_index[1]\n",
    "            size = list(data.edge_attr.size())\n",
    "            size[0] = data.num_nodes * data.num_nodes\n",
    "            edge_attr = data.edge_attr.new_zeros(size)\n",
    "            edge_attr[idx] = data.edge_attr\n",
    "\n",
    "        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
    "        data.edge_attr = edge_attr\n",
    "        data.edge_index = edge_index\n",
    "\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(directory)\n",
    "# transform = T.Compose([MyTransfrom(), Complete(), T.Distance(norm=False)])\n",
    "transform = T.Compose([Complete(), T.Distance(norm=False)])\n",
    "\n",
    "dataset = BioAssayDataset(directory, transform=transform).shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 305679])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.y.view(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[29, 124], edge_index=[2, 812], edge_attr=[812, 5], y=[1], pos=[29, 3], z=[29], name='', idx=[1])\n"
     ]
    }
   ],
   "source": [
    "for x in dataset:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split datasets into train/test\n",
    "\n",
    "td_len = len(dataset)\n",
    "tr_part = round(td_len*0.8)\n",
    "val_part = round(td_len*0.1)\n",
    "\n",
    "test_set = dataset[(tr_part+val_part):]\n",
    "val_set = dataset[tr_part:(tr_part+val_part)]\n",
    "train_set = dataset[:tr_part]\n",
    "\n",
    "train_loader = DataLoader(test_set, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=2160, shuffle=False)\n",
    "val_loader = DataLoader(val_set, batch_size=128, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from layers import GCN, HGPSLPool\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, num_features, n_hid, num_classes, pool_rat, drp_rat, smp_neigh, sprs_att, str_learn, lamb):\n",
    "        super(Model, self).__init__()\n",
    "        # self.args = args\n",
    "        self.num_features = num_features\n",
    "        self.nhid = n_hid\n",
    "        self.num_classes = num_classes\n",
    "        self.pooling_ratio = pool_rat\n",
    "        self.dropout_ratio = drp_rat\n",
    "        self.sample = smp_neigh\n",
    "        self.sparse = sprs_att\n",
    "        self.sl = str_learn\n",
    "        self.lamb = lamb\n",
    "\n",
    "        self.conv1 = GCNConv(self.num_features, self.nhid)\n",
    "        self.conv2 = GCN(self.nhid, self.nhid)\n",
    "        self.conv3 = GCN(self.nhid, self.nhid)\n",
    "\n",
    "        self.pool1 = HGPSLPool(self.nhid, self.pooling_ratio, self.sample, self.sparse, self.sl, self.lamb)\n",
    "        self.pool2 = HGPSLPool(self.nhid, self.pooling_ratio, self.sample, self.sparse, self.sl, self.lamb)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(self.nhid * 2, self.nhid)\n",
    "        self.lin2 = torch.nn.Linear(self.nhid, self.nhid // 2)\n",
    "        self.lin3 = torch.nn.Linear(self.nhid // 2, self.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        edge_attr = None\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x, edge_index, edge_attr, batch = self.pool1(x, edge_index, edge_attr, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_attr))\n",
    "        x, edge_index, edge_attr, batch = self.pool2(x, edge_index, edge_attr, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index, edge_attr))\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(x1) + F.relu(x2) + F.relu(x3)\n",
    "\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=self.dropout_ratio, training=self.training)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.dropout(x, p=self.dropout_ratio, training=self.training)\n",
    "        x = F.log_softmax(self.lin3(x), dim=-1)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser.add_argument('--seed', type=int, default=777, help='random seed')\n",
    "# parser.add_argument('--batch_size', type=int, default=512, help='batch size')\n",
    "# parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "# parser.add_argument('--weight_decay', type=float, default=0.001, help='weight decay')\n",
    "# parser.add_argument('--nhid', type=int, default=128, help='hidden size')\n",
    "# parser.add_argument('--sample_neighbor', type=bool, default=True, help='whether sample neighbors')\n",
    "# parser.add_argument('--sparse_attention', type=bool, default=True, help='whether use sparse attention')\n",
    "# parser.add_argument('--structure_learning', type=bool, default=True, help='whether perform structure learning')\n",
    "# parser.add_argument('--pooling_ratio', type=float, default=0.5, help='pooling ratio')\n",
    "# parser.add_argument('--dropout_ratio', type=float, default=0.0, help='dropout ratio')\n",
    "# parser.add_argument('--lamb', type=float, default=1.0, help='trade-off parameter')\n",
    "# parser.add_argument('--dataset', type=str, default='PROTEINS', help='DD/PROTEINS/NCI1/NCI109/Mutagenicity/ENZYMES')\n",
    "# parser.add_argument('--device', type=str, default='cuda:0', help='specify cuda devices')\n",
    "# parser.add_argument('--epochs', type=int, default=1000, help='maximum number of epochs')\n",
    "# parser.add_argument('--patience', type=int, default=100, help='patience for early stopping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 20\n",
    "BATCH_SIZE = 1000\n",
    "LR = 0.0001\n",
    "WEIGHT_DECAY = 0.001\n",
    "NUM_HIDDEN = 128\n",
    "SMP_NEIGH = True\n",
    "SPRS_ATT = True\n",
    "STR_LEARN = True\n",
    "POOL_RAT = 0.5\n",
    "DRP_RAT = 0.1\n",
    "LAMB = 1.0\n",
    "DSET = None\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEV = device\n",
    "EPOCHS = 300\n",
    "PATIENCE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = dataset.num_features\n",
    "num_classes = dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(num_features, NUM_HIDDEN, num_classes, POOL_RAT, DRP_RAT, SMP_NEIGH, SPRS_ATT, STR_LEARN, LAMB).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    min_loss = 1e10\n",
    "    patience_cnt = 0\n",
    "    val_loss_values = []\n",
    "    best_epoch = 0\n",
    "\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        loss_train = 0.0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            loss = F.nll_loss(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "            pred = out.max(dim=1)[1]\n",
    "            correct += pred.eq(data.y).sum().item()\n",
    "        acc_train = correct / len(train_loader.dataset)\n",
    "        acc_val, loss_val = compute_test(val_loader)\n",
    "        print('Epoch: {:04d}'.format(epoch + 1), 'loss_train: {:.6f}'.format(loss_train),\n",
    "              'acc_train: {:.6f}'.format(acc_train), 'loss_val: {:.6f}'.format(loss_val),\n",
    "              'acc_val: {:.6f}'.format(acc_val), 'time: {:.6f}s'.format(time.time() - t))\n",
    "\n",
    "        val_loss_values.append(loss_val)\n",
    "        torch.save(model.state_dict(), '{}.pth'.format(epoch))\n",
    "        if val_loss_values[-1] < min_loss:\n",
    "            min_loss = val_loss_values[-1]\n",
    "            best_epoch = epoch\n",
    "            patience_cnt = 0\n",
    "        else:\n",
    "            patience_cnt += 1\n",
    "\n",
    "        if patience_cnt == PATIENCE:\n",
    "            break\n",
    "\n",
    "        files = glob.glob('*.pth')\n",
    "        for f in files:\n",
    "            epoch_nb = int(f.split('.')[0])\n",
    "            if epoch_nb < best_epoch:\n",
    "                os.remove(f)\n",
    "\n",
    "    files = glob.glob('*.pth')\n",
    "    for f in files:\n",
    "        epoch_nb = int(f.split('.')[0])\n",
    "        if epoch_nb > best_epoch:\n",
    "            os.remove(f)\n",
    "    print('Optimization Finished! Total time elapsed: {:.6f}'.format(time.time() - t))\n",
    "\n",
    "    return best_epoch\n",
    "\n",
    "\n",
    "def compute_test(loader):\n",
    "    model.eval()\n",
    "    correct = 0.0\n",
    "    loss_test = 0.0\n",
    "    for data in loader:\n",
    "        #add torch nograd fct\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        pred = out.max(dim=1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "        loss_test += F.nll_loss(out, data.y).item()\n",
    "    return correct / len(loader.dataset), loss_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 31.426753 acc_train: 0.991102 loss_val: 8.294160 acc_val: 0.994668 time: 70.791709s\n",
      "Epoch: 0002 loss_train: 7.226860 acc_train: 0.995387 loss_val: 8.235670 acc_val: 0.994668 time: 135.425607s\n",
      "Epoch: 0003 loss_train: 7.215142 acc_train: 0.995387 loss_val: 8.244653 acc_val: 0.994668 time: 199.388845s\n",
      "Epoch: 0004 loss_train: 7.212787 acc_train: 0.995387 loss_val: 8.250591 acc_val: 0.994668 time: 263.874436s\n",
      "Epoch: 0005 loss_train: 7.209829 acc_train: 0.995387 loss_val: 8.251311 acc_val: 0.994668 time: 328.770962s\n",
      "Epoch: 0006 loss_train: 7.206964 acc_train: 0.995387 loss_val: 8.249154 acc_val: 0.994668 time: 393.905252s\n",
      "Epoch: 0007 loss_train: 7.204655 acc_train: 0.995387 loss_val: 8.249029 acc_val: 0.994668 time: 458.622242s\n",
      "Epoch: 0008 loss_train: 7.202559 acc_train: 0.995387 loss_val: 8.248345 acc_val: 0.994668 time: 523.264221s\n",
      "Epoch: 0009 loss_train: 7.200366 acc_train: 0.995387 loss_val: 8.245821 acc_val: 0.994668 time: 587.449852s\n",
      "Epoch: 0010 loss_train: 7.198516 acc_train: 0.995387 loss_val: 8.243606 acc_val: 0.994668 time: 652.403734s\n",
      "Epoch: 0011 loss_train: 7.197006 acc_train: 0.995387 loss_val: 8.242203 acc_val: 0.994668 time: 717.440709s\n",
      "Epoch: 0012 loss_train: 7.195384 acc_train: 0.995387 loss_val: 8.239270 acc_val: 0.994668 time: 781.134748s\n",
      "Epoch: 0013 loss_train: 7.193875 acc_train: 0.995387 loss_val: 8.237537 acc_val: 0.994668 time: 844.973891s\n",
      "Epoch: 0014 loss_train: 7.192370 acc_train: 0.995387 loss_val: 8.235500 acc_val: 0.994668 time: 910.512075s\n",
      "Epoch: 0015 loss_train: 7.191080 acc_train: 0.995387 loss_val: 8.233948 acc_val: 0.994668 time: 975.573051s\n",
      "Epoch: 0016 loss_train: 7.189787 acc_train: 0.995387 loss_val: 8.231716 acc_val: 0.994668 time: 1039.670493s\n",
      "Epoch: 0017 loss_train: 7.188515 acc_train: 0.995387 loss_val: 8.230590 acc_val: 0.994668 time: 1104.485477s\n",
      "Epoch: 0018 loss_train: 7.187269 acc_train: 0.995387 loss_val: 8.230943 acc_val: 0.994668 time: 1169.935287s\n",
      "Epoch: 0019 loss_train: 7.186375 acc_train: 0.995387 loss_val: 8.227605 acc_val: 0.994668 time: 1235.307944s\n",
      "Epoch: 0020 loss_train: 7.185322 acc_train: 0.995387 loss_val: 8.226345 acc_val: 0.994668 time: 1300.477804s\n",
      "Epoch: 0021 loss_train: 7.184434 acc_train: 0.995387 loss_val: 8.225368 acc_val: 0.994668 time: 1365.556755s\n",
      "Epoch: 0022 loss_train: 7.183765 acc_train: 0.995387 loss_val: 8.224426 acc_val: 0.994668 time: 1430.437123s\n",
      "Epoch: 0023 loss_train: 7.182802 acc_train: 0.995387 loss_val: 8.223189 acc_val: 0.994668 time: 1493.705663s\n",
      "Epoch: 0024 loss_train: 7.181848 acc_train: 0.995387 loss_val: 8.221755 acc_val: 0.994668 time: 1556.920042s\n",
      "Epoch: 0025 loss_train: 7.181234 acc_train: 0.995387 loss_val: 8.221093 acc_val: 0.994668 time: 1620.049928s\n",
      "Epoch: 0026 loss_train: 7.180171 acc_train: 0.995387 loss_val: 8.219757 acc_val: 0.994668 time: 1683.290954s\n",
      "Epoch: 0027 loss_train: 7.179310 acc_train: 0.995387 loss_val: 8.219691 acc_val: 0.994668 time: 1746.353790s\n",
      "Epoch: 0028 loss_train: 7.178737 acc_train: 0.995387 loss_val: 8.218124 acc_val: 0.994668 time: 1810.051856s\n",
      "Epoch: 0029 loss_train: 7.178487 acc_train: 0.995387 loss_val: 8.217109 acc_val: 0.994668 time: 1874.273071s\n",
      "Epoch: 0030 loss_train: 7.177247 acc_train: 0.995387 loss_val: 8.216934 acc_val: 0.994668 time: 1939.073382s\n",
      "Epoch: 0031 loss_train: 7.176726 acc_train: 0.995387 loss_val: 8.215510 acc_val: 0.994668 time: 2003.599696s\n",
      "Epoch: 0032 loss_train: 7.176008 acc_train: 0.995387 loss_val: 8.215479 acc_val: 0.994668 time: 2068.207254s\n",
      "Epoch: 0033 loss_train: 7.176586 acc_train: 0.995387 loss_val: 8.217227 acc_val: 0.994668 time: 2133.148396s\n",
      "Epoch: 0034 loss_train: 7.175698 acc_train: 0.995387 loss_val: 8.214852 acc_val: 0.994668 time: 2198.758377s\n",
      "Epoch: 0035 loss_train: 7.174914 acc_train: 0.995387 loss_val: 8.214487 acc_val: 0.994668 time: 2263.454847s\n",
      "Epoch: 0036 loss_train: 7.174095 acc_train: 0.995387 loss_val: 8.213249 acc_val: 0.994668 time: 2327.744486s\n",
      "Epoch: 0037 loss_train: 7.173575 acc_train: 0.995387 loss_val: 8.212614 acc_val: 0.994668 time: 2391.846274s\n",
      "Epoch: 0038 loss_train: 7.172891 acc_train: 0.995387 loss_val: 8.212286 acc_val: 0.994668 time: 2456.440212s\n",
      "Epoch: 0039 loss_train: 7.172341 acc_train: 0.995387 loss_val: 8.211667 acc_val: 0.994668 time: 2521.506273s\n",
      "Epoch: 0040 loss_train: 7.171876 acc_train: 0.995387 loss_val: 8.210531 acc_val: 0.994668 time: 2586.680345s\n",
      "Epoch: 0041 loss_train: 7.171267 acc_train: 0.995387 loss_val: 8.210183 acc_val: 0.994668 time: 2651.569747s\n",
      "Epoch: 0042 loss_train: 7.170860 acc_train: 0.995387 loss_val: 8.209464 acc_val: 0.994668 time: 2716.676640s\n",
      "Epoch: 0043 loss_train: 7.170193 acc_train: 0.995387 loss_val: 8.208668 acc_val: 0.994668 time: 2781.948462s\n",
      "Epoch: 0044 loss_train: 7.169880 acc_train: 0.995387 loss_val: 8.208495 acc_val: 0.994668 time: 2847.181126s\n",
      "Epoch: 0045 loss_train: 7.169353 acc_train: 0.995387 loss_val: 8.207640 acc_val: 0.994668 time: 2912.152345s\n",
      "Epoch: 0046 loss_train: 7.169069 acc_train: 0.995387 loss_val: 8.207429 acc_val: 0.994668 time: 2977.566226s\n",
      "Epoch: 0047 loss_train: 7.168583 acc_train: 0.995387 loss_val: 8.206424 acc_val: 0.994668 time: 3043.441780s\n",
      "Epoch: 0048 loss_train: 7.168046 acc_train: 0.995387 loss_val: 8.206599 acc_val: 0.994668 time: 3109.698847s\n",
      "Epoch: 0049 loss_train: 7.167706 acc_train: 0.995387 loss_val: 8.205773 acc_val: 0.994668 time: 3175.984614s\n",
      "Epoch: 0050 loss_train: 7.167410 acc_train: 0.995387 loss_val: 8.207148 acc_val: 0.994668 time: 3241.226784s\n",
      "Epoch: 0051 loss_train: 7.167133 acc_train: 0.995387 loss_val: 8.204866 acc_val: 0.994668 time: 3307.134739s\n",
      "Epoch: 0052 loss_train: 7.166587 acc_train: 0.995387 loss_val: 8.204798 acc_val: 0.994668 time: 3372.857691s\n",
      "Epoch: 0053 loss_train: 7.166218 acc_train: 0.995387 loss_val: 8.204254 acc_val: 0.994668 time: 3437.713060s\n",
      "Epoch: 0054 loss_train: 7.165890 acc_train: 0.995387 loss_val: 8.209054 acc_val: 0.994668 time: 3503.089536s\n",
      "Epoch: 0055 loss_train: 7.166464 acc_train: 0.995387 loss_val: 8.204275 acc_val: 0.994668 time: 3568.760521s\n",
      "Epoch: 0056 loss_train: 7.165250 acc_train: 0.995387 loss_val: 8.203220 acc_val: 0.994668 time: 3633.918058s\n",
      "Epoch: 0057 loss_train: 7.165550 acc_train: 0.995387 loss_val: 8.202317 acc_val: 0.994668 time: 3699.235680s\n",
      "Epoch: 0058 loss_train: 7.164644 acc_train: 0.995387 loss_val: 8.201949 acc_val: 0.994668 time: 3765.191372s\n",
      "Epoch: 0059 loss_train: 7.164210 acc_train: 0.995387 loss_val: 8.201631 acc_val: 0.994668 time: 3831.101731s\n",
      "Epoch: 0060 loss_train: 7.164347 acc_train: 0.995387 loss_val: 8.201435 acc_val: 0.994668 time: 3896.704268s\n",
      "Epoch: 0061 loss_train: 7.163541 acc_train: 0.995387 loss_val: 8.200822 acc_val: 0.994668 time: 3962.187155s\n",
      "Epoch: 0062 loss_train: 7.162947 acc_train: 0.995387 loss_val: 8.200060 acc_val: 0.994668 time: 4027.656552s\n",
      "Epoch: 0063 loss_train: 7.162960 acc_train: 0.995387 loss_val: 8.200094 acc_val: 0.994668 time: 4093.471027s\n",
      "Epoch: 0064 loss_train: 7.162530 acc_train: 0.995387 loss_val: 8.198939 acc_val: 0.994668 time: 4159.017293s\n",
      "Epoch: 0065 loss_train: 7.162477 acc_train: 0.995387 loss_val: 8.198975 acc_val: 0.994668 time: 4224.526971s\n",
      "Epoch: 0066 loss_train: 7.161888 acc_train: 0.995387 loss_val: 8.199008 acc_val: 0.994668 time: 4289.722764s\n",
      "Epoch: 0067 loss_train: 7.161535 acc_train: 0.995387 loss_val: 8.198024 acc_val: 0.994668 time: 4355.152123s\n",
      "Epoch: 0068 loss_train: 7.160926 acc_train: 0.995387 loss_val: 8.197678 acc_val: 0.994668 time: 4420.033861s\n",
      "Epoch: 0069 loss_train: 7.160624 acc_train: 0.995387 loss_val: 8.197495 acc_val: 0.994668 time: 4484.591282s\n",
      "Epoch: 0070 loss_train: 7.160504 acc_train: 0.995387 loss_val: 8.196260 acc_val: 0.994668 time: 4549.172178s\n",
      "Epoch: 0071 loss_train: 7.160240 acc_train: 0.995387 loss_val: 8.196252 acc_val: 0.994668 time: 4614.153732s\n",
      "Epoch: 0072 loss_train: 7.159743 acc_train: 0.995387 loss_val: 8.196303 acc_val: 0.994668 time: 4678.590525s\n",
      "Epoch: 0073 loss_train: 7.159601 acc_train: 0.995387 loss_val: 8.195946 acc_val: 0.994668 time: 4742.768463s\n",
      "Epoch: 0074 loss_train: 7.159102 acc_train: 0.995387 loss_val: 8.195509 acc_val: 0.994668 time: 4806.964579s\n",
      "Epoch: 0075 loss_train: 7.159442 acc_train: 0.995387 loss_val: 8.195200 acc_val: 0.994668 time: 4871.443920s\n",
      "Epoch: 0076 loss_train: 7.158587 acc_train: 0.995387 loss_val: 8.194820 acc_val: 0.994668 time: 4935.623434s\n",
      "Epoch: 0077 loss_train: 7.158713 acc_train: 0.995387 loss_val: 8.194403 acc_val: 0.994668 time: 5000.147924s\n",
      "Epoch: 0078 loss_train: 7.158548 acc_train: 0.995387 loss_val: 8.194579 acc_val: 0.994668 time: 5064.371786s\n",
      "Epoch: 0079 loss_train: 7.158302 acc_train: 0.995387 loss_val: 8.193016 acc_val: 0.994668 time: 5128.870204s\n",
      "Epoch: 0080 loss_train: 7.157465 acc_train: 0.995387 loss_val: 8.192755 acc_val: 0.994668 time: 5193.685464s\n",
      "Epoch: 0081 loss_train: 7.158020 acc_train: 0.995387 loss_val: 8.192918 acc_val: 0.994668 time: 5257.560898s\n",
      "Epoch: 0082 loss_train: 7.157132 acc_train: 0.995387 loss_val: 8.192359 acc_val: 0.994668 time: 5321.399730s\n",
      "Epoch: 0083 loss_train: 7.156914 acc_train: 0.995387 loss_val: 8.192703 acc_val: 0.994668 time: 5385.063698s\n",
      "Epoch: 0084 loss_train: 7.156502 acc_train: 0.995387 loss_val: 8.191813 acc_val: 0.994668 time: 5448.317527s\n",
      "Epoch: 0085 loss_train: 7.156267 acc_train: 0.995387 loss_val: 8.191520 acc_val: 0.994668 time: 5511.732411s\n",
      "Epoch: 0086 loss_train: 7.155986 acc_train: 0.995387 loss_val: 8.191213 acc_val: 0.994668 time: 5575.309315s\n",
      "Epoch: 0087 loss_train: 7.155753 acc_train: 0.995387 loss_val: 8.190412 acc_val: 0.994668 time: 5640.036869s\n",
      "Epoch: 0088 loss_train: 7.155575 acc_train: 0.995387 loss_val: 8.189622 acc_val: 0.994668 time: 5704.412220s\n",
      "Epoch: 0089 loss_train: 7.155207 acc_train: 0.995387 loss_val: 8.189300 acc_val: 0.994668 time: 5769.037101s\n",
      "Epoch: 0090 loss_train: 7.154947 acc_train: 0.995387 loss_val: 8.188563 acc_val: 0.994668 time: 5833.252283s\n",
      "Epoch: 0091 loss_train: 7.154770 acc_train: 0.995387 loss_val: 8.189011 acc_val: 0.994668 time: 5897.382883s\n",
      "Epoch: 0092 loss_train: 7.154483 acc_train: 0.995387 loss_val: 8.188113 acc_val: 0.994668 time: 5961.778639s\n",
      "Epoch: 0093 loss_train: 7.154435 acc_train: 0.995387 loss_val: 8.187970 acc_val: 0.994668 time: 6026.242966s\n",
      "Epoch: 0094 loss_train: 7.154180 acc_train: 0.995387 loss_val: 8.188051 acc_val: 0.994668 time: 6091.113691s\n",
      "Epoch: 0095 loss_train: 7.153501 acc_train: 0.995387 loss_val: 8.186932 acc_val: 0.994668 time: 6156.250984s\n",
      "Epoch: 0096 loss_train: 7.153383 acc_train: 0.995387 loss_val: 8.186535 acc_val: 0.994668 time: 6221.557356s\n",
      "Epoch: 0097 loss_train: 7.153131 acc_train: 0.995387 loss_val: 8.185874 acc_val: 0.994668 time: 6286.694036s\n",
      "Epoch: 0098 loss_train: 7.152950 acc_train: 0.995387 loss_val: 8.186353 acc_val: 0.994668 time: 6352.076587s\n",
      "Epoch: 0099 loss_train: 7.152593 acc_train: 0.995387 loss_val: 8.185443 acc_val: 0.994668 time: 6417.285315s\n",
      "Epoch: 0100 loss_train: 7.152419 acc_train: 0.995387 loss_val: 8.187486 acc_val: 0.994668 time: 6482.826916s\n",
      "Epoch: 0101 loss_train: 7.152086 acc_train: 0.995387 loss_val: 8.184483 acc_val: 0.994668 time: 6548.436172s\n",
      "Epoch: 0102 loss_train: 7.151623 acc_train: 0.995387 loss_val: 8.185712 acc_val: 0.994668 time: 6613.935825s\n",
      "Epoch: 0103 loss_train: 7.151650 acc_train: 0.995387 loss_val: 8.184970 acc_val: 0.994668 time: 6679.469109s\n",
      "Epoch: 0104 loss_train: 7.151496 acc_train: 0.995387 loss_val: 8.184055 acc_val: 0.994668 time: 6744.253465s\n",
      "Epoch: 0105 loss_train: 7.151368 acc_train: 0.995387 loss_val: 8.183238 acc_val: 0.994668 time: 6807.651979s\n",
      "Epoch: 0106 loss_train: 7.151012 acc_train: 0.995387 loss_val: 8.183039 acc_val: 0.994668 time: 6871.728828s\n",
      "Epoch: 0107 loss_train: 7.150738 acc_train: 0.995387 loss_val: 8.183024 acc_val: 0.994668 time: 6936.008442s\n",
      "Epoch: 0108 loss_train: 7.150614 acc_train: 0.995387 loss_val: 8.182277 acc_val: 0.994668 time: 7000.816036s\n",
      "Epoch: 0109 loss_train: 7.150296 acc_train: 0.995387 loss_val: 8.182174 acc_val: 0.994668 time: 7065.419533s\n",
      "Epoch: 0110 loss_train: 7.150187 acc_train: 0.995387 loss_val: 8.181306 acc_val: 0.994668 time: 7129.956575s\n",
      "Epoch: 0111 loss_train: 7.149662 acc_train: 0.995387 loss_val: 8.181026 acc_val: 0.994668 time: 7195.018221s\n",
      "Epoch: 0112 loss_train: 7.149727 acc_train: 0.995387 loss_val: 8.180857 acc_val: 0.994668 time: 7258.775677s\n",
      "Epoch: 0113 loss_train: 7.149244 acc_train: 0.995387 loss_val: 8.180893 acc_val: 0.994668 time: 7321.857099s\n",
      "Epoch: 0114 loss_train: 7.149216 acc_train: 0.995387 loss_val: 8.179889 acc_val: 0.994668 time: 7384.966010s\n",
      "Epoch: 0115 loss_train: 7.148819 acc_train: 0.995387 loss_val: 8.180335 acc_val: 0.994668 time: 7448.384139s\n",
      "Epoch: 0116 loss_train: 7.148631 acc_train: 0.995387 loss_val: 8.179513 acc_val: 0.994668 time: 7512.101094s\n",
      "Epoch: 0117 loss_train: 7.148771 acc_train: 0.995387 loss_val: 8.178355 acc_val: 0.994668 time: 7575.221720s\n",
      "Epoch: 0118 loss_train: 7.148084 acc_train: 0.995387 loss_val: 8.178595 acc_val: 0.994668 time: 7638.428450s\n",
      "Epoch: 0119 loss_train: 7.148525 acc_train: 0.995387 loss_val: 8.181898 acc_val: 0.994668 time: 7701.544866s\n",
      "Epoch: 0120 loss_train: 7.147996 acc_train: 0.995387 loss_val: 8.179404 acc_val: 0.994668 time: 7765.076692s\n",
      "Epoch: 0121 loss_train: 7.147911 acc_train: 0.995387 loss_val: 8.178141 acc_val: 0.994668 time: 7828.260176s\n",
      "Epoch: 0122 loss_train: 7.147488 acc_train: 0.995387 loss_val: 8.178012 acc_val: 0.994668 time: 7891.701606s\n",
      "Epoch: 0123 loss_train: 7.147085 acc_train: 0.995387 loss_val: 8.177672 acc_val: 0.994668 time: 7954.968836s\n",
      "Epoch: 0124 loss_train: 7.147082 acc_train: 0.995387 loss_val: 8.177478 acc_val: 0.994668 time: 8019.297932s\n",
      "Epoch: 0125 loss_train: 7.146746 acc_train: 0.995387 loss_val: 8.176787 acc_val: 0.994668 time: 8084.112940s\n",
      "Epoch: 0126 loss_train: 7.146462 acc_train: 0.995387 loss_val: 8.176756 acc_val: 0.994668 time: 8148.624569s\n",
      "Epoch: 0127 loss_train: 7.146339 acc_train: 0.995387 loss_val: 8.176506 acc_val: 0.994668 time: 8213.049146s\n",
      "Epoch: 0128 loss_train: 7.146711 acc_train: 0.995387 loss_val: 8.176223 acc_val: 0.994668 time: 8277.676071s\n",
      "Epoch: 0129 loss_train: 7.145815 acc_train: 0.995387 loss_val: 8.176121 acc_val: 0.994668 time: 8342.079148s\n",
      "Epoch: 0130 loss_train: 7.145356 acc_train: 0.995387 loss_val: 8.175267 acc_val: 0.994668 time: 8406.460865s\n",
      "Epoch: 0131 loss_train: 7.145535 acc_train: 0.995387 loss_val: 8.174997 acc_val: 0.994668 time: 8471.942031s\n",
      "Epoch: 0132 loss_train: 7.145185 acc_train: 0.995387 loss_val: 8.174540 acc_val: 0.994668 time: 8536.292019s\n",
      "Epoch: 0133 loss_train: 7.145329 acc_train: 0.995387 loss_val: 8.174354 acc_val: 0.994668 time: 8599.929588s\n",
      "Epoch: 0134 loss_train: 7.144730 acc_train: 0.995387 loss_val: 8.173864 acc_val: 0.994668 time: 8664.353139s\n",
      "Epoch: 0135 loss_train: 7.144600 acc_train: 0.995387 loss_val: 8.173752 acc_val: 0.994668 time: 8728.797404s\n",
      "Epoch: 0136 loss_train: 7.144496 acc_train: 0.995387 loss_val: 8.172943 acc_val: 0.994668 time: 8793.737990s\n",
      "Epoch: 0137 loss_train: 7.144241 acc_train: 0.995387 loss_val: 8.173777 acc_val: 0.994668 time: 8858.050583s\n",
      "Epoch: 0138 loss_train: 7.143832 acc_train: 0.995387 loss_val: 8.173001 acc_val: 0.994668 time: 8921.750838s\n",
      "Epoch: 0139 loss_train: 7.143524 acc_train: 0.995387 loss_val: 8.171907 acc_val: 0.994668 time: 8985.027803s\n",
      "Epoch: 0140 loss_train: 7.143558 acc_train: 0.995387 loss_val: 8.171586 acc_val: 0.994668 time: 9048.553330s\n",
      "Epoch: 0141 loss_train: 7.143236 acc_train: 0.995387 loss_val: 8.171142 acc_val: 0.994668 time: 9111.683588s\n",
      "Epoch: 0142 loss_train: 7.143203 acc_train: 0.995387 loss_val: 8.171721 acc_val: 0.994668 time: 9175.019930s\n",
      "Epoch: 0143 loss_train: 7.142809 acc_train: 0.995387 loss_val: 8.170836 acc_val: 0.994668 time: 9237.863493s\n",
      "Epoch: 0144 loss_train: 7.142553 acc_train: 0.995387 loss_val: 8.170554 acc_val: 0.994668 time: 9300.984061s\n",
      "Epoch: 0145 loss_train: 7.142218 acc_train: 0.995387 loss_val: 8.169734 acc_val: 0.994668 time: 9364.138657s\n",
      "Epoch: 0146 loss_train: 7.142163 acc_train: 0.995387 loss_val: 8.169253 acc_val: 0.994668 time: 9426.951255s\n",
      "Epoch: 0147 loss_train: 7.141965 acc_train: 0.995387 loss_val: 8.169482 acc_val: 0.994668 time: 9491.159422s\n",
      "Epoch: 0148 loss_train: 7.141862 acc_train: 0.995387 loss_val: 8.168912 acc_val: 0.994668 time: 9556.360275s\n",
      "Epoch: 0149 loss_train: 7.141625 acc_train: 0.995387 loss_val: 8.168723 acc_val: 0.994668 time: 9621.233197s\n",
      "Epoch: 0150 loss_train: 7.141433 acc_train: 0.995387 loss_val: 8.168281 acc_val: 0.994668 time: 9686.514460s\n",
      "Epoch: 0151 loss_train: 7.141147 acc_train: 0.995387 loss_val: 8.167891 acc_val: 0.994668 time: 9751.545056s\n",
      "Epoch: 0152 loss_train: 7.140797 acc_train: 0.995387 loss_val: 8.167534 acc_val: 0.994668 time: 9815.730661s\n",
      "Epoch: 0153 loss_train: 7.140646 acc_train: 0.995387 loss_val: 8.167411 acc_val: 0.994668 time: 9880.497029s\n",
      "Epoch: 0154 loss_train: 7.140487 acc_train: 0.995387 loss_val: 8.166697 acc_val: 0.994668 time: 9944.605411s\n",
      "Epoch: 0155 loss_train: 7.140221 acc_train: 0.995387 loss_val: 8.166291 acc_val: 0.994668 time: 10008.969454s\n",
      "Epoch: 0156 loss_train: 7.140051 acc_train: 0.995387 loss_val: 8.166135 acc_val: 0.994668 time: 10073.301918s\n",
      "Epoch: 0157 loss_train: 7.139719 acc_train: 0.995387 loss_val: 8.166016 acc_val: 0.994668 time: 10137.655960s\n",
      "Epoch: 0158 loss_train: 7.139802 acc_train: 0.995387 loss_val: 8.165852 acc_val: 0.994668 time: 10201.732761s\n",
      "Epoch: 0159 loss_train: 7.139620 acc_train: 0.995387 loss_val: 8.165588 acc_val: 0.994668 time: 10265.890586s\n",
      "Epoch: 0160 loss_train: 7.139380 acc_train: 0.995387 loss_val: 8.164496 acc_val: 0.994668 time: 10330.107564s\n",
      "Epoch: 0161 loss_train: 7.138996 acc_train: 0.995387 loss_val: 8.164305 acc_val: 0.994668 time: 10394.613997s\n",
      "Epoch: 0162 loss_train: 7.138657 acc_train: 0.995387 loss_val: 8.163996 acc_val: 0.994668 time: 10459.247560s\n",
      "Epoch: 0163 loss_train: 7.138682 acc_train: 0.995387 loss_val: 8.163889 acc_val: 0.994668 time: 10523.877378s\n",
      "Epoch: 0164 loss_train: 7.138344 acc_train: 0.995387 loss_val: 8.163597 acc_val: 0.994668 time: 10588.936401s\n",
      "Epoch: 0165 loss_train: 7.138517 acc_train: 0.995387 loss_val: 8.163390 acc_val: 0.994668 time: 10654.221730s\n",
      "Epoch: 0166 loss_train: 7.138172 acc_train: 0.995387 loss_val: 8.164353 acc_val: 0.994668 time: 10718.191937s\n",
      "Epoch: 0167 loss_train: 7.137575 acc_train: 0.995387 loss_val: 8.162773 acc_val: 0.994668 time: 10782.289655s\n",
      "Epoch: 0168 loss_train: 7.137711 acc_train: 0.995387 loss_val: 8.162540 acc_val: 0.994668 time: 10846.937559s\n",
      "Epoch: 0169 loss_train: 7.137318 acc_train: 0.995387 loss_val: 8.161985 acc_val: 0.994668 time: 10911.801813s\n",
      "Epoch: 0170 loss_train: 7.137685 acc_train: 0.995387 loss_val: 8.162455 acc_val: 0.994668 time: 10976.194927s\n",
      "Epoch: 0171 loss_train: 7.137341 acc_train: 0.995387 loss_val: 8.162262 acc_val: 0.994668 time: 11040.326374s\n",
      "Epoch: 0172 loss_train: 7.136987 acc_train: 0.995387 loss_val: 8.161252 acc_val: 0.994668 time: 11104.707011s\n",
      "Epoch: 0173 loss_train: 7.136617 acc_train: 0.995387 loss_val: 8.161131 acc_val: 0.994668 time: 11169.356604s\n",
      "Epoch: 0174 loss_train: 7.136532 acc_train: 0.995387 loss_val: 8.160687 acc_val: 0.994668 time: 11233.561301s\n",
      "Epoch: 0175 loss_train: 7.136534 acc_train: 0.995387 loss_val: 8.160118 acc_val: 0.994668 time: 11297.871367s\n",
      "Epoch: 0176 loss_train: 7.136295 acc_train: 0.995387 loss_val: 8.160420 acc_val: 0.994668 time: 11362.215936s\n",
      "Epoch: 0177 loss_train: 7.136216 acc_train: 0.995387 loss_val: 8.160397 acc_val: 0.994668 time: 11427.058094s\n",
      "Epoch: 0178 loss_train: 7.135792 acc_train: 0.995387 loss_val: 8.159660 acc_val: 0.994668 time: 11491.468714s\n",
      "Epoch: 0179 loss_train: 7.135888 acc_train: 0.995387 loss_val: 8.159250 acc_val: 0.994668 time: 11555.504828s\n",
      "Epoch: 0180 loss_train: 7.135720 acc_train: 0.995387 loss_val: 8.159412 acc_val: 0.994668 time: 11620.207633s\n",
      "Epoch: 0181 loss_train: 7.135358 acc_train: 0.995387 loss_val: 8.158977 acc_val: 0.994668 time: 11685.767718s\n",
      "Epoch: 0182 loss_train: 7.135098 acc_train: 0.995387 loss_val: 8.158924 acc_val: 0.994668 time: 11751.348876s\n",
      "Epoch: 0183 loss_train: 7.134866 acc_train: 0.995387 loss_val: 8.158044 acc_val: 0.994668 time: 11815.814413s\n",
      "Epoch: 0184 loss_train: 7.134563 acc_train: 0.995387 loss_val: 8.157763 acc_val: 0.994668 time: 11879.042019s\n",
      "Epoch: 0185 loss_train: 7.134395 acc_train: 0.995387 loss_val: 8.157128 acc_val: 0.994668 time: 11942.640546s\n",
      "Epoch: 0186 loss_train: 7.134228 acc_train: 0.995387 loss_val: 8.156702 acc_val: 0.994668 time: 12006.175856s\n",
      "Epoch: 0187 loss_train: 7.134007 acc_train: 0.995387 loss_val: 8.156389 acc_val: 0.994668 time: 12069.652618s\n",
      "Epoch: 0188 loss_train: 7.133937 acc_train: 0.995387 loss_val: 8.156310 acc_val: 0.994668 time: 12133.065859s\n",
      "Epoch: 0189 loss_train: 7.133735 acc_train: 0.995387 loss_val: 8.156149 acc_val: 0.994668 time: 12196.529701s\n",
      "Epoch: 0190 loss_train: 7.133591 acc_train: 0.995387 loss_val: 8.155109 acc_val: 0.994668 time: 12259.477006s\n",
      "Epoch: 0191 loss_train: 7.133413 acc_train: 0.995387 loss_val: 8.155694 acc_val: 0.994668 time: 12322.755322s\n",
      "Epoch: 0192 loss_train: 7.133339 acc_train: 0.995387 loss_val: 8.155373 acc_val: 0.994668 time: 12385.905747s\n",
      "Epoch: 0193 loss_train: 7.133399 acc_train: 0.995387 loss_val: 8.155038 acc_val: 0.994668 time: 12448.933416s\n",
      "Epoch: 0194 loss_train: 7.132678 acc_train: 0.995387 loss_val: 8.154330 acc_val: 0.994668 time: 12511.701748s\n",
      "Epoch: 0195 loss_train: 7.132670 acc_train: 0.995387 loss_val: 8.154234 acc_val: 0.994668 time: 12574.489879s\n",
      "Epoch: 0196 loss_train: 7.132463 acc_train: 0.995387 loss_val: 8.153829 acc_val: 0.994668 time: 12637.804509s\n",
      "Epoch: 0197 loss_train: 7.132237 acc_train: 0.995387 loss_val: 8.153367 acc_val: 0.994668 time: 12700.527030s\n",
      "Epoch: 0198 loss_train: 7.132416 acc_train: 0.995387 loss_val: 8.154440 acc_val: 0.994668 time: 12763.844151s\n",
      "Epoch: 0199 loss_train: 7.131922 acc_train: 0.995387 loss_val: 8.153143 acc_val: 0.994668 time: 12826.900742s\n",
      "Epoch: 0200 loss_train: 7.131879 acc_train: 0.995387 loss_val: 8.152022 acc_val: 0.994668 time: 12891.134561s\n",
      "Epoch: 0201 loss_train: 7.131423 acc_train: 0.995387 loss_val: 8.152575 acc_val: 0.994668 time: 12954.141091s\n",
      "Epoch: 0202 loss_train: 7.131541 acc_train: 0.995387 loss_val: 8.152783 acc_val: 0.994668 time: 13017.938255s\n",
      "Epoch: 0203 loss_train: 7.131166 acc_train: 0.995387 loss_val: 8.152300 acc_val: 0.994668 time: 13081.555682s\n",
      "Epoch: 0204 loss_train: 7.131221 acc_train: 0.995387 loss_val: 8.152230 acc_val: 0.994668 time: 13145.135667s\n",
      "Epoch: 0205 loss_train: 7.131034 acc_train: 0.995387 loss_val: 8.152134 acc_val: 0.994668 time: 13208.699012s\n",
      "Epoch: 0206 loss_train: 7.130897 acc_train: 0.995387 loss_val: 8.151499 acc_val: 0.994668 time: 13272.485167s\n",
      "Epoch: 0207 loss_train: 7.130840 acc_train: 0.995387 loss_val: 8.151463 acc_val: 0.994668 time: 13336.090398s\n",
      "Epoch: 0208 loss_train: 7.130490 acc_train: 0.995387 loss_val: 8.151151 acc_val: 0.994668 time: 13399.920680s\n",
      "Epoch: 0209 loss_train: 7.130337 acc_train: 0.995387 loss_val: 8.150650 acc_val: 0.994668 time: 13463.587355s\n",
      "Epoch: 0210 loss_train: 7.130070 acc_train: 0.995387 loss_val: 8.150276 acc_val: 0.994668 time: 13527.678845s\n",
      "Epoch: 0211 loss_train: 7.130471 acc_train: 0.995387 loss_val: 8.150891 acc_val: 0.994668 time: 13591.791779s\n",
      "Epoch: 0212 loss_train: 7.129789 acc_train: 0.995387 loss_val: 8.149550 acc_val: 0.994668 time: 13655.892412s\n",
      "Epoch: 0213 loss_train: 7.129848 acc_train: 0.995387 loss_val: 8.150266 acc_val: 0.994668 time: 13719.844036s\n",
      "Epoch: 0214 loss_train: 7.129355 acc_train: 0.995387 loss_val: 8.149144 acc_val: 0.994668 time: 13783.632113s\n",
      "Epoch: 0215 loss_train: 7.129611 acc_train: 0.995387 loss_val: 8.149353 acc_val: 0.994668 time: 13847.256187s\n",
      "Epoch: 0216 loss_train: 7.129259 acc_train: 0.995387 loss_val: 8.149206 acc_val: 0.994668 time: 13910.894339s\n",
      "Epoch: 0217 loss_train: 7.128981 acc_train: 0.995387 loss_val: 8.147985 acc_val: 0.994668 time: 13974.467801s\n",
      "Epoch: 0218 loss_train: 7.129076 acc_train: 0.995387 loss_val: 8.148042 acc_val: 0.994668 time: 14038.836087s\n",
      "Epoch: 0219 loss_train: 7.128684 acc_train: 0.995387 loss_val: 8.147579 acc_val: 0.994668 time: 14103.342429s\n",
      "Epoch: 0220 loss_train: 7.128469 acc_train: 0.995387 loss_val: 8.147521 acc_val: 0.994668 time: 14167.583282s\n",
      "Epoch: 0221 loss_train: 7.128309 acc_train: 0.995387 loss_val: 8.146805 acc_val: 0.994668 time: 14231.671350s\n",
      "Epoch: 0222 loss_train: 7.128162 acc_train: 0.995387 loss_val: 8.146444 acc_val: 0.994668 time: 14295.207431s\n",
      "Epoch: 0223 loss_train: 7.127821 acc_train: 0.995387 loss_val: 8.145997 acc_val: 0.994668 time: 14358.450670s\n",
      "Epoch: 0224 loss_train: 7.127899 acc_train: 0.995387 loss_val: 8.146165 acc_val: 0.994668 time: 14421.668531s\n",
      "Epoch: 0225 loss_train: 7.127475 acc_train: 0.995387 loss_val: 8.145523 acc_val: 0.994668 time: 14485.806286s\n",
      "Epoch: 0226 loss_train: 7.127580 acc_train: 0.995387 loss_val: 8.145512 acc_val: 0.994668 time: 14550.308106s\n",
      "Epoch: 0227 loss_train: 7.127505 acc_train: 0.995387 loss_val: 8.145262 acc_val: 0.994668 time: 14614.358807s\n",
      "Epoch: 0228 loss_train: 7.127067 acc_train: 0.995387 loss_val: 8.144470 acc_val: 0.994668 time: 14678.820301s\n",
      "Epoch: 0229 loss_train: 7.127376 acc_train: 0.995387 loss_val: 8.144412 acc_val: 0.994668 time: 14743.036325s\n",
      "Epoch: 0230 loss_train: 7.127140 acc_train: 0.995387 loss_val: 8.145855 acc_val: 0.994668 time: 14807.520905s\n",
      "Epoch: 0231 loss_train: 7.126547 acc_train: 0.995387 loss_val: 8.144282 acc_val: 0.994668 time: 14871.703009s\n",
      "Epoch: 0232 loss_train: 7.126436 acc_train: 0.995387 loss_val: 8.143745 acc_val: 0.994668 time: 14935.782019s\n",
      "Epoch: 0233 loss_train: 7.126369 acc_train: 0.995387 loss_val: 8.143499 acc_val: 0.994668 time: 14999.964649s\n",
      "Epoch: 0234 loss_train: 7.126134 acc_train: 0.995387 loss_val: 8.142627 acc_val: 0.994668 time: 15064.387966s\n",
      "Epoch: 0235 loss_train: 7.126016 acc_train: 0.995387 loss_val: 8.142745 acc_val: 0.994668 time: 15128.466117s\n",
      "Epoch: 0236 loss_train: 7.126055 acc_train: 0.995387 loss_val: 8.142540 acc_val: 0.994668 time: 15192.929213s\n",
      "Epoch: 0237 loss_train: 7.125766 acc_train: 0.995387 loss_val: 8.142231 acc_val: 0.994668 time: 15257.915923s\n",
      "Epoch: 0238 loss_train: 7.125686 acc_train: 0.995387 loss_val: 8.142111 acc_val: 0.994668 time: 15323.148234s\n",
      "Epoch: 0239 loss_train: 7.125363 acc_train: 0.995387 loss_val: 8.141324 acc_val: 0.994668 time: 15388.605682s\n",
      "Epoch: 0240 loss_train: 7.125311 acc_train: 0.995387 loss_val: 8.141523 acc_val: 0.994668 time: 15453.514301s\n",
      "Epoch: 0241 loss_train: 7.125386 acc_train: 0.995387 loss_val: 8.141167 acc_val: 0.994668 time: 15517.981663s\n",
      "Epoch: 0242 loss_train: 7.124856 acc_train: 0.995387 loss_val: 8.140559 acc_val: 0.994668 time: 15582.360896s\n",
      "Epoch: 0243 loss_train: 7.124861 acc_train: 0.995387 loss_val: 8.141377 acc_val: 0.994668 time: 15645.823792s\n",
      "Epoch: 0244 loss_train: 7.124575 acc_train: 0.995387 loss_val: 8.140147 acc_val: 0.994668 time: 15709.157801s\n",
      "Epoch: 0245 loss_train: 7.124516 acc_train: 0.995387 loss_val: 8.139685 acc_val: 0.994668 time: 15772.280985s\n",
      "Epoch: 0246 loss_train: 7.124310 acc_train: 0.995387 loss_val: 8.139697 acc_val: 0.994668 time: 15836.346368s\n",
      "Epoch: 0247 loss_train: 7.124138 acc_train: 0.995387 loss_val: 8.139500 acc_val: 0.994668 time: 15899.511753s\n",
      "Epoch: 0248 loss_train: 7.123979 acc_train: 0.995387 loss_val: 8.139018 acc_val: 0.994668 time: 15962.669087s\n",
      "Epoch: 0249 loss_train: 7.123891 acc_train: 0.995387 loss_val: 8.138271 acc_val: 0.994668 time: 16025.628514s\n",
      "Epoch: 0250 loss_train: 7.123813 acc_train: 0.995387 loss_val: 8.138482 acc_val: 0.994668 time: 16089.206764s\n",
      "Epoch: 0251 loss_train: 7.123431 acc_train: 0.995387 loss_val: 8.138275 acc_val: 0.994668 time: 16153.747154s\n",
      "Epoch: 0252 loss_train: 7.123533 acc_train: 0.995387 loss_val: 8.138020 acc_val: 0.994668 time: 16218.309180s\n",
      "Epoch: 0253 loss_train: 7.123203 acc_train: 0.995387 loss_val: 8.137083 acc_val: 0.994668 time: 16282.684963s\n",
      "Epoch: 0254 loss_train: 7.123028 acc_train: 0.995387 loss_val: 8.137031 acc_val: 0.994668 time: 16346.727715s\n",
      "Epoch: 0255 loss_train: 7.123023 acc_train: 0.995387 loss_val: 8.137176 acc_val: 0.994668 time: 16411.012632s\n",
      "Epoch: 0256 loss_train: 7.122949 acc_train: 0.995387 loss_val: 8.137575 acc_val: 0.994668 time: 16475.559934s\n",
      "Epoch: 0257 loss_train: 7.122730 acc_train: 0.995387 loss_val: 8.137325 acc_val: 0.994668 time: 16539.005447s\n",
      "Epoch: 0258 loss_train: 7.122600 acc_train: 0.995387 loss_val: 8.136639 acc_val: 0.994668 time: 16602.231616s\n",
      "Epoch: 0259 loss_train: 7.122647 acc_train: 0.995387 loss_val: 8.136307 acc_val: 0.994668 time: 16665.546053s\n",
      "Epoch: 0260 loss_train: 7.122082 acc_train: 0.995387 loss_val: 8.135963 acc_val: 0.994668 time: 16728.647422s\n",
      "Epoch: 0261 loss_train: 7.122086 acc_train: 0.995387 loss_val: 8.135560 acc_val: 0.994668 time: 16791.811866s\n",
      "Epoch: 0262 loss_train: 7.121946 acc_train: 0.995387 loss_val: 8.135299 acc_val: 0.994668 time: 16854.907517s\n",
      "Epoch: 0263 loss_train: 7.121674 acc_train: 0.995387 loss_val: 8.134782 acc_val: 0.994668 time: 16918.276645s\n",
      "Epoch: 0264 loss_train: 7.121584 acc_train: 0.995387 loss_val: 8.134682 acc_val: 0.994668 time: 16981.465786s\n",
      "Epoch: 0265 loss_train: 7.121556 acc_train: 0.995387 loss_val: 8.134755 acc_val: 0.994668 time: 17044.506932s\n",
      "Epoch: 0266 loss_train: 7.121622 acc_train: 0.995387 loss_val: 8.135171 acc_val: 0.994668 time: 17107.993674s\n",
      "Epoch: 0267 loss_train: 7.121370 acc_train: 0.995387 loss_val: 8.134985 acc_val: 0.994668 time: 17171.209068s\n",
      "Epoch: 0268 loss_train: 7.120848 acc_train: 0.995387 loss_val: 8.133862 acc_val: 0.994668 time: 17234.441804s\n",
      "Epoch: 0269 loss_train: 7.120871 acc_train: 0.995387 loss_val: 8.133411 acc_val: 0.994668 time: 17297.774359s\n",
      "Epoch: 0270 loss_train: 7.121110 acc_train: 0.995387 loss_val: 8.133877 acc_val: 0.994668 time: 17361.234509s\n",
      "Epoch: 0271 loss_train: 7.120580 acc_train: 0.995387 loss_val: 8.133592 acc_val: 0.994668 time: 17424.997529s\n",
      "Epoch: 0272 loss_train: 7.120780 acc_train: 0.995387 loss_val: 8.133594 acc_val: 0.994668 time: 17488.057025s\n",
      "Epoch: 0273 loss_train: 7.120147 acc_train: 0.995387 loss_val: 8.131924 acc_val: 0.994668 time: 17551.166376s\n",
      "Epoch: 0274 loss_train: 7.120130 acc_train: 0.995387 loss_val: 8.131648 acc_val: 0.994668 time: 17614.206312s\n",
      "Epoch: 0275 loss_train: 7.120130 acc_train: 0.995387 loss_val: 8.131754 acc_val: 0.994668 time: 17678.607006s\n",
      "Epoch: 0276 loss_train: 7.119733 acc_train: 0.995387 loss_val: 8.131458 acc_val: 0.994668 time: 17742.394819s\n",
      "Epoch: 0277 loss_train: 7.119982 acc_train: 0.995387 loss_val: 8.131140 acc_val: 0.994668 time: 17806.074582s\n",
      "Epoch: 0278 loss_train: 7.119486 acc_train: 0.995387 loss_val: 8.130706 acc_val: 0.994668 time: 17869.859792s\n",
      "Epoch: 0279 loss_train: 7.119493 acc_train: 0.995387 loss_val: 8.130507 acc_val: 0.994668 time: 17934.562272s\n",
      "Epoch: 0280 loss_train: 7.119377 acc_train: 0.995387 loss_val: 8.133531 acc_val: 0.994668 time: 17999.464785s\n",
      "Epoch: 0281 loss_train: 7.119433 acc_train: 0.995387 loss_val: 8.130880 acc_val: 0.994668 time: 18064.158681s\n",
      "Epoch: 0282 loss_train: 7.118939 acc_train: 0.995387 loss_val: 8.130130 acc_val: 0.994668 time: 18128.829147s\n",
      "Epoch: 0283 loss_train: 7.118987 acc_train: 0.995387 loss_val: 8.129552 acc_val: 0.994668 time: 18193.056983s\n",
      "Epoch: 0284 loss_train: 7.118607 acc_train: 0.995387 loss_val: 8.128927 acc_val: 0.994668 time: 18257.295572s\n",
      "Epoch: 0285 loss_train: 7.118685 acc_train: 0.995387 loss_val: 8.128981 acc_val: 0.994668 time: 18322.457267s\n",
      "Epoch: 0286 loss_train: 7.118620 acc_train: 0.995387 loss_val: 8.128951 acc_val: 0.994668 time: 18387.408005s\n",
      "Epoch: 0287 loss_train: 7.118217 acc_train: 0.995387 loss_val: 8.128464 acc_val: 0.994668 time: 18450.720422s\n",
      "Epoch: 0288 loss_train: 7.118059 acc_train: 0.995387 loss_val: 8.127814 acc_val: 0.994668 time: 18514.109439s\n",
      "Epoch: 0289 loss_train: 7.118019 acc_train: 0.995387 loss_val: 8.127620 acc_val: 0.994668 time: 18577.651419s\n",
      "Epoch: 0290 loss_train: 7.117978 acc_train: 0.995387 loss_val: 8.127647 acc_val: 0.994668 time: 18641.778764s\n",
      "Epoch: 0291 loss_train: 7.117814 acc_train: 0.995387 loss_val: 8.126699 acc_val: 0.994668 time: 18705.056348s\n",
      "Epoch: 0292 loss_train: 7.117692 acc_train: 0.995387 loss_val: 8.126468 acc_val: 0.994668 time: 18769.406534s\n",
      "Epoch: 0293 loss_train: 7.117489 acc_train: 0.995387 loss_val: 8.125838 acc_val: 0.994668 time: 18834.050105s\n",
      "Epoch: 0294 loss_train: 7.117258 acc_train: 0.995387 loss_val: 8.126980 acc_val: 0.994668 time: 18897.696699s\n",
      "Epoch: 0295 loss_train: 7.117025 acc_train: 0.995387 loss_val: 8.127058 acc_val: 0.994668 time: 18960.987005s\n",
      "Epoch: 0296 loss_train: 7.116844 acc_train: 0.995387 loss_val: 8.125716 acc_val: 0.994668 time: 19024.226688s\n",
      "Epoch: 0297 loss_train: 7.116841 acc_train: 0.995387 loss_val: 8.126020 acc_val: 0.994668 time: 19087.185556s\n",
      "Epoch: 0298 loss_train: 7.116549 acc_train: 0.995387 loss_val: 8.125075 acc_val: 0.994668 time: 19150.359909s\n",
      "Epoch: 0299 loss_train: 7.116676 acc_train: 0.995387 loss_val: 8.125315 acc_val: 0.994668 time: 19213.623838s\n",
      "Epoch: 0300 loss_train: 7.116400 acc_train: 0.995387 loss_val: 8.126386 acc_val: 0.994668 time: 19278.075240s\n",
      "Optimization Finished! Total time elapsed: 19278.077166\n"
     ]
    }
   ],
   "source": [
    "model_out = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = 297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(num_features, NUM_HIDDEN, num_classes, POOL_RAT, DRP_RAT, SMP_NEIGH, SPRS_ATT, STR_LEARN, LAMB).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(f'{best_model}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/hgp_sl.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/hgp_sl.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(model_out))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_out' is not defined"
     ]
    }
   ],
   "source": [
    "print('{}'.format(model_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364032"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.84 GiB (GPU 0; 7.79 GiB total capacity; 1.48 GiB already allocated; 2.48 GiB free; 2.94 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/hgp_sl.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/hgp_sl.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m test_acc, test_loss \u001b[39m=\u001b[39m compute_test(test_loader)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/hgp_sl.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest set results, loss = \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m, accuracy = \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(test_loss, test_acc))\n",
      "\u001b[1;32m/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/hgp_sl.ipynb Cell 32\u001b[0m in \u001b[0;36mcompute_test\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/hgp_sl.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m loader:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/hgp_sl.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/hgp_sl.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m     out \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/hgp_sl.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m     pred \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/hgp_sl.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m     correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39meq(data\u001b[39m.\u001b[39my)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/assay_geo/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/hgp_sl.ipynb Cell 32\u001b[0m in \u001b[0;36mModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/hgp_sl.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m edge_attr \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/hgp_sl.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x, edge_index, edge_attr))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/hgp_sl.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m x, edge_index, edge_attr, batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpool1(x, edge_index, edge_attr, batch)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/hgp_sl.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m x1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([gmp(x, batch), gap(x, batch)], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/hgp_sl.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x, edge_index, edge_attr))\n",
      "File \u001b[0;32m~/anaconda3/envs/assay_geo/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_GNN/HGP-SL/layers.py:213\u001b[0m, in \u001b[0;36mHGPSLPool.forward\u001b[0;34m(self, x, edge_index, edge_attr, batch)\u001b[0m\n\u001b[1;32m    211\u001b[0m weights \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39mcat([x[row], x[col]], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matt)\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    212\u001b[0m weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mleaky_relu(weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnegative_slop) \u001b[39m+\u001b[39m new_edge_attr \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlamb\n\u001b[0;32m--> 213\u001b[0m adj \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mzeros((x\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m), x\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m)), dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat, device\u001b[39m=\u001b[39;49mx\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    214\u001b[0m adj[row, col] \u001b[39m=\u001b[39m weights\n\u001b[1;32m    215\u001b[0m new_edge_index, weights \u001b[39m=\u001b[39m dense_to_sparse(adj)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.84 GiB (GPU 0; 7.79 GiB total capacity; 1.48 GiB already allocated; 2.48 GiB free; 2.94 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "test_acc, test_loss = compute_test(test_loader)\n",
    "print('Test set results, loss = {:.6f}, accuracy = {:.6f}'.format(test_loss, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('assay_geo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbcbd352f3a1bc1f772970a8ec0a6a21791151c1068f88a3a88dc0a1196b67fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
