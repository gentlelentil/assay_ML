{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathaniel/anaconda3/envs/assay_ML/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import enlighten\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import SVG, Image, display\n",
    "\n",
    "#RDKit related imports\n",
    "from rdkit import RDLogger\n",
    "from rdkit.Chem import PandasTools, AllChem as Chem, Descriptors\n",
    "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import DataStructs\n",
    "\n",
    "#scikit imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, validation_curve\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "RDLogger.logger().setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Normalization, Dropout\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.callbacks import History, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF binary classification\n",
    "\n",
    "def create_model(inp):\n",
    "\n",
    "    optimiser = Adam(learning_rate=0.005)\n",
    "    model = Sequential()\n",
    "    # model.add(normaliser)\n",
    "    model.add(Dense(60, input_shape=(inp.shape[1],), activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(60, input_shape=(inp.shape[1],), activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='glorot_normal'))\n",
    "\n",
    "\n",
    "    model.compile(optimizer=optimiser, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = History()\n",
    "red_LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001, min_delta=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF binary classification\n",
    "\n",
    "def create_model(inp):\n",
    "\n",
    "    optimiser = Adam(learning_rate=0.005)\n",
    "    model = Sequential()\n",
    "    # model.add(normaliser)\n",
    "    model.add(Dense(60, input_shape=(inp.shape[1],), activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(60, input_shape=(inp.shape[1],), activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='glorot_normal'))\n",
    "\n",
    "\n",
    "    model.compile(optimizer=optimiser, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_x_mmap = np.load('./adasyn/x_ecfpada.npy', mmap_mode='r')\n",
    "ada_y_mmap = np.load('./adasyn/y_ecfpada.npy', mmap_mode='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_generator import data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30000\n",
    "dim = ada_x_mmap.shape[1]\n",
    "classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = data_generator(ada_x_mmap, ada_y_mmap, dim, batch_size, n_classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 15:49:40.054875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-14 15:49:40.086524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-14 15:49:40.086676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-14 15:49:40.087103: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 15:49:40.087526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-14 15:49:40.087631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-14 15:49:40.087724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-14 15:49:40.381775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-14 15:49:40.381920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-14 15:49:40.382016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-14 15:49:40.382083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5746 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "ADA_ecfp6_mod = create_model(ada_x_mmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADA_ecfp6_mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_784724/3004161045.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  ADA_ecfp6_mod.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048,)\n",
      "(2048, 1)\n",
      "(30000, 2048, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (2048,) into shape (2048,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_RF_TensorFlow/ada_syn.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_RF_TensorFlow/ada_syn.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m ADA_ecfp6_mod\u001b[39m.\u001b[39;49mfit_generator(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_RF_TensorFlow/ada_syn.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     generator\u001b[39m=\u001b[39;49mtraining_generator,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_RF_TensorFlow/ada_syn.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_RF_TensorFlow/ada_syn.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     workers\u001b[39m=\u001b[39;49m\u001b[39m6\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfmp-ws/home/nathaniel/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_RF_TensorFlow/ada_syn.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/assay_ML/lib/python3.10/site-packages/keras/engine/training.py:2260\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2249\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2250\u001b[0m \n\u001b[1;32m   2251\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2252\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[1;32m   2253\u001b[0m \u001b[39m  this endpoint.\u001b[39;00m\n\u001b[1;32m   2254\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2255\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2256\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2257\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2258\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   2259\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m-> 2260\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   2261\u001b[0m     generator,\n\u001b[1;32m   2262\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   2263\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   2264\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2265\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   2266\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m   2267\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   2268\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m   2269\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   2270\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2271\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2272\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2273\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   2274\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch)\n",
      "File \u001b[0;32m~/anaconda3/envs/assay_ML/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_RF_TensorFlow/custom_generator.py:44\u001b[0m, in \u001b[0;36mdata_generator.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     41\u001b[0m tmp_list_IDs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlist_IDs[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m indexes]\n\u001b[1;32m     43\u001b[0m \u001b[39m#generate data\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__generate_data(tmp_list_IDs)\n\u001b[1;32m     46\u001b[0m \u001b[39mreturn\u001b[39;00m x, y\n",
      "File \u001b[0;32m~/Desktop/ASSAY_ML_BASE/tree_1/assay_ML/ML_RF_TensorFlow/custom_generator.py:65\u001b[0m, in \u001b[0;36mdata_generator.__generate_data\u001b[0;34m(self, tmp_list_IDs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mprint\u001b[39m(X\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     64\u001b[0m \u001b[39mfor\u001b[39;00m ID, i \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tmp_list_IDs):\n\u001b[0;32m---> 65\u001b[0m     X[ID,] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_data[i]\n\u001b[1;32m     66\u001b[0m     Y[ID] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_data[i]\n\u001b[1;32m     69\u001b[0m \u001b[39mreturn\u001b[39;00m X, Y\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (2048,) into shape (2048,1)"
     ]
    }
   ],
   "source": [
    "ADA_ecfp6_mod.fit_generator(\n",
    "    generator=training_generator,\n",
    "    use_multiprocessing=True,\n",
    "    workers=6,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('assay_ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b575e0092b85cca1a2ef5012346d2f4eed50c68ed69b2460935d27dc8cbca99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
