{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import enlighten\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import SVG, Image, display\n",
    "\n",
    "#RDKit related imports\n",
    "from rdkit import RDLogger\n",
    "from rdkit.Chem import PandasTools, AllChem as Chem, Descriptors\n",
    "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "#scikit imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "RDLogger.logger().setLevel(RDLogger.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 09:38:04.743254: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-04 09:38:04.776766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-04 09:38:04.824842: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/nathaniel/MS_frag/boost_1_71_0/lib:~MS_frag/rdkit-Release_2017_09_3/lib:/home/nathaniel/MS_frag/lp_solve_5.5/lpsolve55/bin/ux64\n",
      "2022-08-04 09:38:04.824855: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_used_desc = ['MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge', 'Ipc']\n",
    "desc_calc = MolecularDescriptorCalculator([x for x in [x[0] for x in Descriptors.descList] if x not in not_used_desc])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'backup_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/nathaniel/Desktop/PhD/projects/assay_ML/ML_RF_TensorFlow/RF_TF.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nathaniel/Desktop/PhD/projects/assay_ML/ML_RF_TensorFlow/RF_TF.ipynb#ch0000003?line=0'>1</a>\u001b[0m cols \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mbackup_df.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, nrows\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nathaniel/Desktop/PhD/projects/assay_ML/ML_RF_TensorFlow/RF_TF.ipynb#ch0000003?line=1'>2</a>\u001b[0m dataframe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mbackup_df.csv\u001b[39m\u001b[39m'\u001b[39m, index_col\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, usecols\u001b[39m=\u001b[39mcols[\u001b[39m1\u001b[39m:])\n",
      "File \u001b[0;32m~/anaconda3/envs/assay_ML/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/assay_ML/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/assay_ML/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/assay_ML/lib/python3.10/site-packages/pandas/io/parsers/readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/anaconda3/envs/assay_ML/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1219\u001b[0m     f,\n\u001b[1;32m   1220\u001b[0m     mode,\n\u001b[1;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1227\u001b[0m )\n\u001b[1;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/assay_ML/lib/python3.10/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    787\u001b[0m             handle,\n\u001b[1;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    792\u001b[0m         )\n\u001b[1;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'backup_df.csv'"
     ]
    }
   ],
   "source": [
    "cols = pd.read_csv('backup_df.csv', nrows=1).columns\n",
    "dataframe = pd.read_csv('backup_df.csv', index_col=False, usecols=cols[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PandasTools.AddMoleculeColumnToFrame(dataframe, 'PUBCHEM_CANONICAL_SMILES', 'ROMol', includeFingerprints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_dataset = dataframe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "</style>\n",
       "<div class=\"enlighten\">\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>Calculating molecular descriptors 100%|████████████████| 305449/305449 [27:10&lt;00:00, 187.40 ticks/s]</pre>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mol_descs = []\n",
    "activity_binary = []\n",
    "activity_regressor = []\n",
    "ECFP6s = []\n",
    "topols = []\n",
    "atom_pairs = []\n",
    "\n",
    "\n",
    "\n",
    "pbar = enlighten.Counter(total=len(RF_dataset.index), desc='Calculating molecular descriptors', unit='ticks')\n",
    "\n",
    "for ID, row in RF_dataset.iterrows():\n",
    "    # print(i)\n",
    "    nan_flag = False\n",
    "\n",
    "    mol = row.ROMol# if i == max_radius else row[f'FRAG_R{i}']          \n",
    "    descriptor = desc_calc.CalcDescriptors(mol)\n",
    "    for j in descriptor:\n",
    "        if np.isnan(j):\n",
    "            nan_flag = True\n",
    "            break \n",
    "    if nan_flag:\n",
    "        print(ID)\n",
    "        print(f'Line {ID} contains NaN values, removing...')\n",
    "        RF_dataset.drop(ID, inplace=True)\n",
    "        continue\n",
    "\n",
    "    ECFP6_vec = Chem.GetMorganFingerprintAsBitVect(mol, radius=3)\n",
    "    topol_vec =  Chem.GetHashedTopologicalTorsionFingerprintAsBitVect(mol)\n",
    "    atpair_vec = Chem.GetHashedAtomPairFingerprintAsBitVect(mol)\n",
    "\n",
    "    ECFP6s.append(ECFP6_vec)\n",
    "    topols.append(topol_vec)\n",
    "    atom_pairs.append(atpair_vec)\n",
    "\n",
    "\n",
    "\n",
    "    # print(descriptor)\n",
    "    mol_descs.append(descriptor)\n",
    "    activity_binary.append(row.PUBCHEM_ACTIVITY_OUTCOME)\n",
    "    activity_regressor.append(row.PUBCHEM_ACTIVITY_SCORE)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305449\n"
     ]
    }
   ],
   "source": [
    "print(len(topols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (979687259.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [18]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for i in feat_lists:\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "feat_lists = [mol_descs, ECFP6s, topols, atom_pairs]\n",
    "feat_names = ['Descriptors', 'ECFP6', 'Topologies', 'Atom Pairs']\n",
    "\n",
    "assert len(feat_lists) == len(feat_names)\n",
    "\n",
    "# for ID, i in enumerate(feat_lists):\n",
    "#     newlist = feat_lists.remove(ID)\n",
    "#     for j in newlist:\n",
    "#         print(len(i))\n",
    "#         print(len(j))\n",
    "#         assert len(i) == len(j)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305449\n",
      "305449\n",
      "305449\n",
      "203\n"
     ]
    }
   ],
   "source": [
    "print(len(mol_descs))\n",
    "print(len(activity_binary))\n",
    "print(len(activity_regressor))\n",
    "print(len(desc_calc.descriptorNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(mol_descs, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_df = pd.DataFrame(arr, columns=desc_calc.descriptorNames)\n",
    "model_df['PUBCHEM_ACTIVITY_OUTCOME'] = activity_binary\n",
    "model_df['PUBCHEM_ACTIVITY_SCORE'] = activity_regressor\n",
    "\n",
    "model_df.to_csv('RF_TF_desc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    len(model_df.index)\n",
    "except:\n",
    "    model_df = pd.read_csv('RF_TF_desc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_df.drop('Ipc', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_binary = np.ravel(model_df['PUBCHEM_ACTIVITY_OUTCOME'])\n",
    "activity_regressor = np.ravel(model_df['PUBCHEM_ACTIVITY_SCORE'])\n",
    "del model_df['PUBCHEM_ACTIVITY_OUTCOME']\n",
    "del model_df['PUBCHEM_ACTIVITY_SCORE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_bin_vec = []\n",
    "\n",
    "for i in activity_binary:\n",
    "    if i == 'Active':\n",
    "        act_bin_vec.append(1)\n",
    "    elif i == 'Inactive':\n",
    "        act_bin_vec.append(0)\n",
    "    else:\n",
    "        print(\"Invalid data in array, remove all non Active/Inactive cells\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 fold CV\n",
    "folds = 5\n",
    "seed = 2022\n",
    "\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "spl = list(kf.split(mol_descs, act_bin_vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for iname, iset in zip(feat_names, feat_lists):\n",
    "#     for jname, jset in zip(feat_names, feat_lists):\n",
    "#         if iname == jname:\n",
    "#             continue\n",
    "#         est = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = model_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the descriptors\n",
    "X_train, X_test, Y_BIN_train, Y_BIN_test, Y_REG_train, Y_REG_test = train_test_split(model_df, activity_binary, activity_regressor, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Inactive' 'Inactive' 'Inactive' ... 'Inactive' 'Inactive' 'Inactive']\n",
      "369\n",
      "76363\n"
     ]
    }
   ],
   "source": [
    "#remove inactives from the training set\n",
    "print(Y_BIN_test)\n",
    "\n",
    "actives = 0\n",
    "for i in Y_BIN_test:\n",
    "    if i == 'Active':\n",
    "        actives += 1 \n",
    "\n",
    "print(actives)\n",
    "print(len(Y_BIN_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_no_inactives = np.array([i for i in Y_BIN_test if i == 'Active'])\n",
    "\n",
    "act_index = np.argwhere(Y_BIN_test=='Inactive')\n",
    "x_test_no_inactives = np.delete(X_test, act_index, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369,)\n",
      "(369, 203)\n"
     ]
    }
   ],
   "source": [
    "print(y_test_no_inactives.shape)\n",
    "print(x_test_no_inactives.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BINARY\n",
    "test_descriptor_df = pd.DataFrame(X_test, columns=desc_calc.descriptorNames)\n",
    "\n",
    "test_descriptor_df['PUBCHEM_ACTIVITY_OUTCOME'] = Y_BIN_test\n",
    "\n",
    "train_descriptor_df = pd.DataFrame(X_train, columns=desc_calc.descriptorNames)\n",
    "train_descriptor_df['PUBCHEM_ACTIVITY_OUTCOME'] = Y_BIN_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_descriptor_df2 = pd.DataFrame(x_test_no_inactives, columns=desc_calc.descriptorNames)\n",
    "test_descriptor_df2['PUBCHEM_ACTIVITY_OUTCOME'] = y_test_no_inactives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "NUM_TREES = 2000\n",
    "\n",
    "MIN_EXAMPLES = 6\n",
    "\n",
    "MAX_DEPTH = 5\n",
    "\n",
    "SUBSAMPLE = 0.65\n",
    "\n",
    "SAMPLING_METHOD = \"RANDOM\"\n",
    "\n",
    "VALIDATION_RATIO = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_RF_model(model, train_data, test_data, num_epochs=1, batch_size=1):\n",
    "    train_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(\n",
    "        train_data, label='PUBCHEM_ACTIVITY_OUTCOME'\n",
    "    )\n",
    "    test_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(\n",
    "        test_data, label='PUBCHEM_ACTIVITY_OUTCOME'\n",
    "    )\n",
    "    model.fit(train_dataset, epochs=num_epochs, batch_size=batch_size)\n",
    "    _, accuracy = model.evaluate(test_dataset, verbose=0)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_usage():\n",
    "    feature_usages = []\n",
    "\n",
    "    #there are only numerical descriptors\n",
    "    for feature_name in desc_calc.descriptorNames:\n",
    "        usage = tfdf.keras.FeatureUsage(name=feature_name, semantic=tfdf.keras.FeatureSemantic.NUMERICAL)\n",
    "        feature_usages.append(usage)\n",
    "\n",
    "    return feature_usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_GBT_model():\n",
    "    gbt_model = tfdf.keras.GradientBoostedTreesModel(\n",
    "        features=show_feature_usage(),\n",
    "        exclude_non_specified_features=True,\n",
    "        num_trees=NUM_TREES,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        min_examples=MIN_EXAMPLES,\n",
    "        subsample=SUBSAMPLE,\n",
    "        validation_ratio=VALIDATION_RATIO,\n",
    "        task=tfdf.keras.Task.CLASSIFICATION,\n",
    "    )\n",
    "    gbt_model.compile(metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\")])\n",
    "    return gbt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmp_9pe0_4s as temporary training directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 12:06:10.056556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 12:06:10.056742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 12:06:10.056835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 12:06:10.057096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 12:06:10.057194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 12:06:10.057285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 12:06:10.057408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 12:06:10.057503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 12:06:10.057563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5274 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gbt_model1 = create_GBT_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpxsoc_fda as temporary training directory\n"
     ]
    }
   ],
   "source": [
    "gbt_model2 = create_GBT_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_RF_model(gbt_model1, train_data=train_descriptor_df, test_data=test_descriptor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_RF_model(gbt_model2, train_data=train_descriptor_df, test_data=test_descriptor_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gbt_model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_descriptor_df = pd.DataFrame(X_test, columns=[desc_calc.descriptorNames])\n",
    "train_descriptor_df['PUBCHEM_ACTIVITY_OUTCOME'] = Y1_test\n",
    "train_descriptor_df['PUBCHEM_ACTIVITY_SCORE'] = Y2_test"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b575e0092b85cca1a2ef5012346d2f4eed50c68ed69b2460935d27dc8cbca99"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 ('assay_ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
